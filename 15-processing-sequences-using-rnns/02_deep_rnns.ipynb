{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "532a4abb-fe48-444b-881d-463c0d15c794",
   "metadata": {},
   "source": [
    "# Deep RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92319f82-02d7-4bc1-acbb-1b125182be8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## First Using a simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f42f276-84ff-4895-b0c6-eed8073ca52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 16:42:35.239522: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 16:42:35.323299: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 16:42:37.043174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db819db-feee-41e6-8b58-b50755424c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"datasets/ridership/CTA_-_Ridership_-_Daily_Boarding_Totals.csv\")\n",
    "df = pd.read_csv(path, parse_dates=[\"service_date\"])\n",
    "# 将数据框的列名更改为较短的形式，以提高代码的可读性。\n",
    "df.columns = [\"date\", \"day_type\", \"bus\", \"rail\", \"total\"]\n",
    "# 根据日期列对数据框进行排序，并将日期列设置为数据框的索引。\n",
    "df = df.sort_values(\"date\").set_index(\"date\")\n",
    "# no need for total, it's just bus + rail\n",
    "df = df.drop(\"total\", axis=1)\n",
    "# remove duplicated months (2011-10 and 2014-07)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "rail_train = df[\"rail\"][\"2016-01\":\"2018-12\"] / 1e6\n",
    "rail_valid = df[\"rail\"][\"2019-01\":\"2019-05\"] / 1e6\n",
    "rail_test = df[\"rail\"][\"2019-06\"]\n",
    "\n",
    "seq_length = 56\n",
    "tf.random.set_seed(42)\n",
    "train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    rail_train.to_numpy(),\n",
    "    targets=rail_train[seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    rail_valid.to_numpy(),\n",
    "    targets=rail_valid[seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c6ad0b-2ef8-43f6-97b9-ef1e63db4b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9573d42-df20-439c-80f2-94912c0c20a5",
   "metadata": {},
   "source": [
    "解释下这段代码：  \n",
    "1. `model = tf.keras.Sequential([...])`: 创建一个顺序模型。\n",
    "2. `tf.keras.layers.SimpleRNN(1, input_shape=[None, 1])`: 向模型中添加一个简单的循环神经网络层。具体参数解释如下：\n",
    "    * 1: 表示该 RNN 层中的神经元数量为 1。\n",
    "    * input_shape=[None, 1]: 指定输入序列的形状。这里表示输入序列的长度可以是任意值（None），每个时间步有一个特征（1维）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0bd3b4-f068-445b-b253-f936a2604af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate(model, train_set, valid_set, learning_rate, epochs=500):\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_mae\", patience=50, restore_best_weights=True)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "    history = model.fit(train_set, validation_data=valid_set, epochs=epochs, callbacks=[early_stopping_cb])\n",
    "    valid_loss, valid_mae = model.evaluate(valid_set)\n",
    "    return valid_mae * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "768ca026-50cc-46be-b226-1bcd2835bec9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 2s 21ms/step - loss: 0.1349 - mae: 0.3937 - val_loss: 0.0741 - val_mae: 0.3434\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0590 - mae: 0.2941 - val_loss: 0.0517 - val_mae: 0.2721\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0279 - mae: 0.1707 - val_loss: 0.0152 - val_mae: 0.1261\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0147 - mae: 0.1563 - val_loss: 0.0139 - val_mae: 0.1377\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0142 - mae: 0.1498 - val_loss: 0.0139 - val_mae: 0.1348\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0140 - mae: 0.1500 - val_loss: 0.0138 - val_mae: 0.1332\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0139 - mae: 0.1481 - val_loss: 0.0136 - val_mae: 0.1328\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0137 - mae: 0.1479 - val_loss: 0.0135 - val_mae: 0.1316\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0136 - mae: 0.1467 - val_loss: 0.0134 - val_mae: 0.1300\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0134 - mae: 0.1456 - val_loss: 0.0132 - val_mae: 0.1313\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0133 - mae: 0.1449 - val_loss: 0.0130 - val_mae: 0.1312\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0132 - mae: 0.1443 - val_loss: 0.0130 - val_mae: 0.1292\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0131 - mae: 0.1428 - val_loss: 0.0128 - val_mae: 0.1297\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0130 - mae: 0.1436 - val_loss: 0.0127 - val_mae: 0.1298\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0129 - mae: 0.1425 - val_loss: 0.0127 - val_mae: 0.1286\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1409 - val_loss: 0.0126 - val_mae: 0.1268\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0127 - mae: 0.1419 - val_loss: 0.0125 - val_mae: 0.1280\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0126 - mae: 0.1395 - val_loss: 0.0125 - val_mae: 0.1258\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0125 - mae: 0.1385 - val_loss: 0.0124 - val_mae: 0.1258\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0125 - mae: 0.1396 - val_loss: 0.0123 - val_mae: 0.1256\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0124 - mae: 0.1372 - val_loss: 0.0123 - val_mae: 0.1245\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0123 - mae: 0.1367 - val_loss: 0.0122 - val_mae: 0.1245\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0123 - mae: 0.1374 - val_loss: 0.0121 - val_mae: 0.1237\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0122 - mae: 0.1362 - val_loss: 0.0121 - val_mae: 0.1230\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0121 - mae: 0.1355 - val_loss: 0.0120 - val_mae: 0.1227\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0121 - mae: 0.1356 - val_loss: 0.0120 - val_mae: 0.1220\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0120 - mae: 0.1346 - val_loss: 0.0119 - val_mae: 0.1218\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0120 - mae: 0.1335 - val_loss: 0.0119 - val_mae: 0.1217\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0119 - mae: 0.1344 - val_loss: 0.0118 - val_mae: 0.1210\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0119 - mae: 0.1324 - val_loss: 0.0118 - val_mae: 0.1205\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0118 - mae: 0.1329 - val_loss: 0.0117 - val_mae: 0.1205\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0118 - mae: 0.1316 - val_loss: 0.0118 - val_mae: 0.1191\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0117 - mae: 0.1315 - val_loss: 0.0116 - val_mae: 0.1202\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0117 - mae: 0.1313 - val_loss: 0.0116 - val_mae: 0.1193\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0116 - mae: 0.1306 - val_loss: 0.0115 - val_mae: 0.1191\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0116 - mae: 0.1301 - val_loss: 0.0115 - val_mae: 0.1186\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0115 - mae: 0.1295 - val_loss: 0.0115 - val_mae: 0.1185\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0115 - mae: 0.1296 - val_loss: 0.0114 - val_mae: 0.1179\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0114 - mae: 0.1285 - val_loss: 0.0114 - val_mae: 0.1182\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0114 - mae: 0.1284 - val_loss: 0.0113 - val_mae: 0.1179\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0114 - mae: 0.1283 - val_loss: 0.0113 - val_mae: 0.1177\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0113 - mae: 0.1279 - val_loss: 0.0112 - val_mae: 0.1174\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0113 - mae: 0.1274 - val_loss: 0.0112 - val_mae: 0.1172\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0112 - mae: 0.1270 - val_loss: 0.0112 - val_mae: 0.1164\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0112 - mae: 0.1259 - val_loss: 0.0111 - val_mae: 0.1164\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0112 - mae: 0.1264 - val_loss: 0.0111 - val_mae: 0.1162\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0111 - mae: 0.1261 - val_loss: 0.0110 - val_mae: 0.1159\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0111 - mae: 0.1256 - val_loss: 0.0110 - val_mae: 0.1156\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0110 - mae: 0.1246 - val_loss: 0.0110 - val_mae: 0.1150\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0110 - mae: 0.1246 - val_loss: 0.0109 - val_mae: 0.1150\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0110 - mae: 0.1243 - val_loss: 0.0109 - val_mae: 0.1149\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0109 - mae: 0.1242 - val_loss: 0.0109 - val_mae: 0.1144\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0109 - mae: 0.1234 - val_loss: 0.0108 - val_mae: 0.1141\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0109 - mae: 0.1234 - val_loss: 0.0108 - val_mae: 0.1136\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0108 - mae: 0.1226 - val_loss: 0.0108 - val_mae: 0.1135\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0108 - mae: 0.1223 - val_loss: 0.0107 - val_mae: 0.1132\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0108 - mae: 0.1227 - val_loss: 0.0107 - val_mae: 0.1131\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0107 - mae: 0.1218 - val_loss: 0.0107 - val_mae: 0.1121\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0107 - mae: 0.1217 - val_loss: 0.0106 - val_mae: 0.1122\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0107 - mae: 0.1213 - val_loss: 0.0106 - val_mae: 0.1119\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0107 - mae: 0.1206 - val_loss: 0.0106 - val_mae: 0.1114\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0106 - mae: 0.1208 - val_loss: 0.0106 - val_mae: 0.1112\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0106 - mae: 0.1200 - val_loss: 0.0106 - val_mae: 0.1108\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0106 - mae: 0.1203 - val_loss: 0.0105 - val_mae: 0.1105\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0106 - mae: 0.1193 - val_loss: 0.0105 - val_mae: 0.1100\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0106 - mae: 0.1191 - val_loss: 0.0105 - val_mae: 0.1099\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0105 - mae: 0.1194 - val_loss: 0.0105 - val_mae: 0.1095\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0105 - mae: 0.1190 - val_loss: 0.0104 - val_mae: 0.1094\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0105 - mae: 0.1187 - val_loss: 0.0104 - val_mae: 0.1089\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0105 - mae: 0.1184 - val_loss: 0.0104 - val_mae: 0.1087\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0105 - mae: 0.1180 - val_loss: 0.0104 - val_mae: 0.1085\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0105 - mae: 0.1176 - val_loss: 0.0104 - val_mae: 0.1081\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0105 - mae: 0.1179 - val_loss: 0.0104 - val_mae: 0.1079\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1171 - val_loss: 0.0104 - val_mae: 0.1076\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1175 - val_loss: 0.0103 - val_mae: 0.1076\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1169 - val_loss: 0.0104 - val_mae: 0.1071\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1170 - val_loss: 0.0103 - val_mae: 0.1071\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1167 - val_loss: 0.0103 - val_mae: 0.1069\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1165 - val_loss: 0.0103 - val_mae: 0.1067\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1162 - val_loss: 0.0103 - val_mae: 0.1065\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0104 - mae: 0.1158 - val_loss: 0.0103 - val_mae: 0.1063\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0104 - mae: 0.1159 - val_loss: 0.0103 - val_mae: 0.1062\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1158 - val_loss: 0.0103 - val_mae: 0.1059\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1156 - val_loss: 0.0103 - val_mae: 0.1058\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1155 - val_loss: 0.0103 - val_mae: 0.1056\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1151 - val_loss: 0.0103 - val_mae: 0.1055\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0104 - mae: 0.1153 - val_loss: 0.0103 - val_mae: 0.1054\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1151 - val_loss: 0.0103 - val_mae: 0.1052\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0104 - mae: 0.1153 - val_loss: 0.0102 - val_mae: 0.1053\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1150 - val_loss: 0.0103 - val_mae: 0.1051\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1147 - val_loss: 0.0103 - val_mae: 0.1048\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1147 - val_loss: 0.0102 - val_mae: 0.1049\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1151 - val_loss: 0.0103 - val_mae: 0.1047\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1147 - val_loss: 0.0102 - val_mae: 0.1047\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0104 - mae: 0.1144 - val_loss: 0.0103 - val_mae: 0.1044\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1145 - val_loss: 0.0102 - val_mae: 0.1044\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1144 - val_loss: 0.0103 - val_mae: 0.1043\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1142 - val_loss: 0.0103 - val_mae: 0.1042\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1141 - val_loss: 0.0103 - val_mae: 0.1041\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1145 - val_loss: 0.0102 - val_mae: 0.1042\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1141 - val_loss: 0.0102 - val_mae: 0.1040\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1140 - val_loss: 0.0103 - val_mae: 0.1040\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1141 - val_loss: 0.0103 - val_mae: 0.1039\n",
      "Epoch 104/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1142 - val_loss: 0.0102 - val_mae: 0.1039\n",
      "Epoch 105/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0104 - mae: 0.1138 - val_loss: 0.0103 - val_mae: 0.1038\n",
      "Epoch 106/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1141 - val_loss: 0.0102 - val_mae: 0.1038\n",
      "Epoch 107/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1137 - val_loss: 0.0103 - val_mae: 0.1037\n",
      "Epoch 108/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0104 - mae: 0.1140 - val_loss: 0.0103 - val_mae: 0.1037\n",
      "Epoch 109/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1136 - val_loss: 0.0102 - val_mae: 0.1037\n",
      "Epoch 110/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0104 - mae: 0.1142 - val_loss: 0.0103 - val_mae: 0.1036\n",
      "Epoch 111/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1135 - val_loss: 0.0103 - val_mae: 0.1036\n",
      "Epoch 112/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1137 - val_loss: 0.0102 - val_mae: 0.1036\n",
      "Epoch 113/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1141 - val_loss: 0.0103 - val_mae: 0.1035\n",
      "Epoch 114/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1136 - val_loss: 0.0103 - val_mae: 0.1035\n",
      "Epoch 115/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1035\n",
      "Epoch 116/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1138 - val_loss: 0.0102 - val_mae: 0.1036\n",
      "Epoch 117/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1135 - val_loss: 0.0103 - val_mae: 0.1034\n",
      "Epoch 118/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1137 - val_loss: 0.0103 - val_mae: 0.1034\n",
      "Epoch 119/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0102 - val_mae: 0.1034\n",
      "Epoch 120/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1136 - val_loss: 0.0103 - val_mae: 0.1033\n",
      "Epoch 121/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1033\n",
      "Epoch 122/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0103 - val_mae: 0.1032\n",
      "Epoch 123/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0102 - val_mae: 0.1033\n",
      "Epoch 124/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1032\n",
      "Epoch 125/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0103 - val_mae: 0.1032\n",
      "Epoch 126/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0103 - val_mae: 0.1031\n",
      "Epoch 127/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1136 - val_loss: 0.0103 - val_mae: 0.1032\n",
      "Epoch 128/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0103 - val_mae: 0.1032\n",
      "Epoch 129/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0103 - mae: 0.1134 - val_loss: 0.0102 - val_mae: 0.1032\n",
      "Epoch 130/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1032\n",
      "Epoch 131/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1135 - val_loss: 0.0103 - val_mae: 0.1031\n",
      "Epoch 132/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0104 - mae: 0.1136 - val_loss: 0.0102 - val_mae: 0.1031\n",
      "Epoch 133/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1031\n",
      "Epoch 134/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1031\n",
      "Epoch 135/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1133 - val_loss: 0.0103 - val_mae: 0.1031\n",
      "Epoch 136/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1031\n",
      "Epoch 137/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1031\n",
      "Epoch 138/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0102 - val_mae: 0.1031\n",
      "Epoch 139/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1031\n",
      "Epoch 140/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 141/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0102 - val_mae: 0.1031\n",
      "Epoch 142/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0102 - val_mae: 0.1031\n",
      "Epoch 143/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 144/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 145/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 146/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 147/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 148/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 149/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 150/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 151/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 152/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 153/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 154/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 155/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 156/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 157/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 158/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 159/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 160/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 161/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 162/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 163/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 164/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 165/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 166/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 167/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1031\n",
      "Epoch 168/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 169/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 170/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 171/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 172/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 173/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0102 - val_mae: 0.1031\n",
      "Epoch 174/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 175/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 176/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0102 - val_mae: 0.1031\n",
      "Epoch 177/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 178/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 179/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 180/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 181/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 182/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 183/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 184/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0102 - val_mae: 0.1032\n",
      "Epoch 185/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 186/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 187/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 188/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1127 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 189/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1129 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 190/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 191/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1127 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 192/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 193/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 194/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 195/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 196/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 197/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 198/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 199/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 200/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 201/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 202/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 203/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 204/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 205/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 206/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0102 - val_mae: 0.1031\n",
      "Epoch 207/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 208/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1127 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 209/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 210/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 211/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1031\n",
      "Epoch 212/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 213/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 214/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 215/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 216/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1127 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 217/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 218/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 219/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 220/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 221/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 222/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1125 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 223/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 224/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 225/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 226/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 227/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 228/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 229/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 230/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 231/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 232/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 233/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 234/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 235/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 236/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 237/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 238/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 239/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0102 - val_mae: 0.1032\n",
      "Epoch 240/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 241/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 242/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 243/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 244/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 245/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0102 - val_mae: 0.1031\n",
      "Epoch 246/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 247/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 248/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 249/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1133 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 250/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 251/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 252/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 253/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1127 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 254/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 255/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 256/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 257/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 258/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 259/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 260/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 261/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 262/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 263/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 264/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 265/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 266/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 267/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 268/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1127 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 269/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 270/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 271/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.1126 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102811.00869178772"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_and_evaluate(model, train_ds, valid_ds, learning_rate=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5a9e0da-44c6-4acb-88fa-638638309c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 102811.00869178772"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ede191-f850-487c-873b-37f5471c121f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deep RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a6a53f-ca50-4ddc-a80e-164c8963057b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 单层 SimpleRNN 和多层 SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232c9a04-de2f-4109-aa4e-6acea82b2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
    "univar_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 1]),\n",
    "    tf.keras.layers.Dense(1)  # no activation function by default\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d18ee-2aad-4119-b1fc-bc3b796ea8f6",
   "metadata": {},
   "source": [
    "这样的模型结构适用于单变量时间序列的预测任务，其中每个时间步的输入是一个标量（1维特征），模型通过 RNN 层学习时间序列中的模式，并通过最后的密集连接层生成预测值。  \n",
    "1. `tf.keras.layers.SimpleRNN(32, input_shape=[None, 1])`: 向模型中添加一个简单的循环神经网络（RNN）层。具体参数解释如下：\n",
    "    * 32: 表示 RNN 层中的神经元数量为 32。\n",
    "    * input_shape=[None, 1]: 指定输入序列的形状。这里表示输入序列的长度可以是任意值（None），每个时间步有一个特征（1维）。\n",
    "2. `tf.keras.layers.Dense(1)`: 向模型中添加一个密集连接层（全连接层），具有一个神经元。在此层中，默认情况下没有激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17b731fa-ebf9-4f72-9011-233dd6e2542b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 2s 20ms/step - loss: 0.0144 - mae: 0.1306 - val_loss: 0.0057 - val_mae: 0.0859\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0045 - mae: 0.0645 - val_loss: 0.0025 - val_mae: 0.0484\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0034 - mae: 0.0524 - val_loss: 0.0021 - val_mae: 0.0378\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0034 - mae: 0.0527 - val_loss: 0.0023 - val_mae: 0.0419\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0500 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0032 - mae: 0.0542 - val_loss: 0.0020 - val_mae: 0.0361\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0034 - mae: 0.0539 - val_loss: 0.0022 - val_mae: 0.0372\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0028 - mae: 0.0458 - val_loss: 0.0021 - val_mae: 0.0351\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0486 - val_loss: 0.0028 - val_mae: 0.0543\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0507 - val_loss: 0.0021 - val_mae: 0.0353\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0492 - val_loss: 0.0022 - val_mae: 0.0378\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0027 - mae: 0.0451 - val_loss: 0.0020 - val_mae: 0.0357\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0027 - mae: 0.0463 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0026 - mae: 0.0430 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0028 - mae: 0.0460 - val_loss: 0.0022 - val_mae: 0.0419\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0028 - mae: 0.0471 - val_loss: 0.0027 - val_mae: 0.0515\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0506 - val_loss: 0.0019 - val_mae: 0.0363\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0026 - mae: 0.0445 - val_loss: 0.0025 - val_mae: 0.0446\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0027 - mae: 0.0457 - val_loss: 0.0020 - val_mae: 0.0361\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0025 - mae: 0.0415 - val_loss: 0.0018 - val_mae: 0.0343\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0026 - mae: 0.0434 - val_loss: 0.0022 - val_mae: 0.0389\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0026 - mae: 0.0431 - val_loss: 0.0028 - val_mae: 0.0537\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0028 - mae: 0.0460 - val_loss: 0.0021 - val_mae: 0.0401\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0028 - mae: 0.0466 - val_loss: 0.0019 - val_mae: 0.0332\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0028 - mae: 0.0471 - val_loss: 0.0022 - val_mae: 0.0430\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0027 - mae: 0.0464 - val_loss: 0.0019 - val_mae: 0.0316\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0429 - val_loss: 0.0021 - val_mae: 0.0384\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0025 - mae: 0.0422 - val_loss: 0.0020 - val_mae: 0.0352\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0027 - mae: 0.0451 - val_loss: 0.0023 - val_mae: 0.0436\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0025 - mae: 0.0424 - val_loss: 0.0021 - val_mae: 0.0365\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0025 - mae: 0.0444 - val_loss: 0.0021 - val_mae: 0.0371\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0518 - val_loss: 0.0022 - val_mae: 0.0409\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0028 - mae: 0.0471 - val_loss: 0.0032 - val_mae: 0.0569\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0026 - mae: 0.0462 - val_loss: 0.0020 - val_mae: 0.0346\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0024 - mae: 0.0412 - val_loss: 0.0019 - val_mae: 0.0326\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0025 - mae: 0.0418 - val_loss: 0.0020 - val_mae: 0.0366\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0025 - mae: 0.0448 - val_loss: 0.0020 - val_mae: 0.0354\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0025 - mae: 0.0435 - val_loss: 0.0023 - val_mae: 0.0394\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0027 - mae: 0.0464 - val_loss: 0.0027 - val_mae: 0.0521\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0509 - val_loss: 0.0020 - val_mae: 0.0354\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0026 - mae: 0.0448 - val_loss: 0.0023 - val_mae: 0.0417\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0027 - mae: 0.0459 - val_loss: 0.0023 - val_mae: 0.0437\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0025 - mae: 0.0446 - val_loss: 0.0025 - val_mae: 0.0434\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0026 - mae: 0.0446 - val_loss: 0.0023 - val_mae: 0.0393\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0024 - mae: 0.0414 - val_loss: 0.0023 - val_mae: 0.0429\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0024 - mae: 0.0417 - val_loss: 0.0019 - val_mae: 0.0321\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0024 - mae: 0.0407 - val_loss: 0.0026 - val_mae: 0.0471\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0026 - mae: 0.0454 - val_loss: 0.0019 - val_mae: 0.0313\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0024 - mae: 0.0401 - val_loss: 0.0020 - val_mae: 0.0405\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 0.0019 - val_mae: 0.0359\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0024 - mae: 0.0411 - val_loss: 0.0021 - val_mae: 0.0413\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0025 - mae: 0.0441 - val_loss: 0.0020 - val_mae: 0.0379\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0025 - mae: 0.0427 - val_loss: 0.0019 - val_mae: 0.0349\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0026 - mae: 0.0449 - val_loss: 0.0019 - val_mae: 0.0356\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0026 - mae: 0.0456 - val_loss: 0.0018 - val_mae: 0.0331\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0024 - mae: 0.0424 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0024 - mae: 0.0428 - val_loss: 0.0025 - val_mae: 0.0460\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0025 - mae: 0.0434 - val_loss: 0.0023 - val_mae: 0.0402\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0024 - mae: 0.0418 - val_loss: 0.0020 - val_mae: 0.0363\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0025 - mae: 0.0419 - val_loss: 0.0020 - val_mae: 0.0388\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0026 - mae: 0.0455 - val_loss: 0.0019 - val_mae: 0.0365\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0024 - mae: 0.0424 - val_loss: 0.0019 - val_mae: 0.0326\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0024 - mae: 0.0425 - val_loss: 0.0021 - val_mae: 0.0376\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0024 - mae: 0.0414 - val_loss: 0.0023 - val_mae: 0.0421\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0025 - mae: 0.0438 - val_loss: 0.0020 - val_mae: 0.0323\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0024 - mae: 0.0410 - val_loss: 0.0019 - val_mae: 0.0357\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0023 - mae: 0.0395 - val_loss: 0.0022 - val_mae: 0.0431\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0024 - mae: 0.0425 - val_loss: 0.0020 - val_mae: 0.0333\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0024 - mae: 0.0427 - val_loss: 0.0020 - val_mae: 0.0345\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0025 - mae: 0.0423 - val_loss: 0.0019 - val_mae: 0.0348\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0024 - mae: 0.0431 - val_loss: 0.0020 - val_mae: 0.0356\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0023 - mae: 0.0397 - val_loss: 0.0019 - val_mae: 0.0354\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0024 - mae: 0.0412 - val_loss: 0.0022 - val_mae: 0.0428\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0024 - mae: 0.0414 - val_loss: 0.0018 - val_mae: 0.0348\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0024 - mae: 0.0432 - val_loss: 0.0020 - val_mae: 0.0394\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0023 - mae: 0.0412 - val_loss: 0.0020 - val_mae: 0.0353\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0023 - mae: 0.0405 - val_loss: 0.0019 - val_mae: 0.0348\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0023 - mae: 0.0392 - val_loss: 0.0019 - val_mae: 0.0344\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0023 - mae: 0.0411 - val_loss: 0.0020 - val_mae: 0.0354\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0023 - mae: 0.0402 - val_loss: 0.0019 - val_mae: 0.0378\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0024 - mae: 0.0423 - val_loss: 0.0020 - val_mae: 0.0332\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0023 - mae: 0.0398 - val_loss: 0.0020 - val_mae: 0.0387\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0024 - mae: 0.0422 - val_loss: 0.0019 - val_mae: 0.0326\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0023 - mae: 0.0407 - val_loss: 0.0020 - val_mae: 0.0398\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0022 - mae: 0.0408 - val_loss: 0.0021 - val_mae: 0.0373\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0023 - mae: 0.0406 - val_loss: 0.0019 - val_mae: 0.0321\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0023 - mae: 0.0409 - val_loss: 0.0018 - val_mae: 0.0350\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0023 - mae: 0.0399 - val_loss: 0.0019 - val_mae: 0.0355\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0025 - mae: 0.0432 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0024 - mae: 0.0418 - val_loss: 0.0020 - val_mae: 0.0380\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0022 - mae: 0.0401 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0023 - mae: 0.0403 - val_loss: 0.0018 - val_mae: 0.0352\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0022 - mae: 0.0408 - val_loss: 0.0020 - val_mae: 0.0343\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0023 - mae: 0.0416 - val_loss: 0.0019 - val_mae: 0.0341\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0023 - mae: 0.0400 - val_loss: 0.0020 - val_mae: 0.0376\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0023 - mae: 0.0395 - val_loss: 0.0020 - val_mae: 0.0373\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0023 - mae: 0.0398 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0022 - mae: 0.0403 - val_loss: 0.0019 - val_mae: 0.0357\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31252.723187208176"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – compiles, fits, and evaluates the model, like earlier\n",
    "fit_and_evaluate(univar_model, train_ds, valid_ds, learning_rate=0.05)  # return 29473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97fddc4e-c70a-4aac-9813-fa7cdf0900a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "deep_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 1]),\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(32),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a6358-393a-4e62-a003-035195296cf4",
   "metadata": {},
   "source": [
    "这部分定义了一个深层次的时间序列模型 deep_model。具体解释如下：\n",
    "1. tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 1]): 添加一个 SimpleRNN 层，返回完整的输出序列（return_sequences=True），并指定输入序列的形状。\n",
    "\n",
    "2. tf.keras.layers.SimpleRNN(32, return_sequences=True): 添加第二个 SimpleRNN 层，同样返回完整的输出序列。\n",
    "\n",
    "3. tf.keras.layers.SimpleRNN(32): 添加第三个 SimpleRNN 层，不再返回完整的输出序列，而只返回最后一个时间步的输出。\n",
    "\n",
    "4. tf.keras.layers.Dense(1): 添加一个密集连接层，用于生成最终的预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f74f90d-68da-4dbd-81e5-14cd49beb4df",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 4s 49ms/step - loss: 0.0336 - mae: 0.1599 - val_loss: 0.0044 - val_mae: 0.0792\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0067 - mae: 0.0884 - val_loss: 0.0032 - val_mae: 0.0625\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0063 - mae: 0.0842 - val_loss: 0.0027 - val_mae: 0.0522\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0047 - mae: 0.0675 - val_loss: 0.0038 - val_mae: 0.0665\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0042 - mae: 0.0603 - val_loss: 0.0044 - val_mae: 0.0736\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0043 - mae: 0.0622 - val_loss: 0.0024 - val_mae: 0.0446\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0041 - mae: 0.0600 - val_loss: 0.0032 - val_mae: 0.0607\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0042 - mae: 0.0594 - val_loss: 0.0021 - val_mae: 0.0372\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0043 - mae: 0.0620 - val_loss: 0.0025 - val_mae: 0.0464\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0042 - mae: 0.0610 - val_loss: 0.0037 - val_mae: 0.0658\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0035 - mae: 0.0529 - val_loss: 0.0020 - val_mae: 0.0352\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0034 - mae: 0.0509 - val_loss: 0.0037 - val_mae: 0.0662\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0034 - mae: 0.0517 - val_loss: 0.0021 - val_mae: 0.0387\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0035 - mae: 0.0530 - val_loss: 0.0029 - val_mae: 0.0529\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 1s 38ms/step - loss: 0.0038 - mae: 0.0551 - val_loss: 0.0021 - val_mae: 0.0387\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0034 - mae: 0.0531 - val_loss: 0.0044 - val_mae: 0.0756\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0035 - mae: 0.0524 - val_loss: 0.0026 - val_mae: 0.0486\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0032 - mae: 0.0495 - val_loss: 0.0027 - val_mae: 0.0477\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0035 - mae: 0.0532 - val_loss: 0.0020 - val_mae: 0.0355\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0034 - mae: 0.0530 - val_loss: 0.0019 - val_mae: 0.0328\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0032 - mae: 0.0508 - val_loss: 0.0020 - val_mae: 0.0321\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0019 - val_mae: 0.0327\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0032 - mae: 0.0503 - val_loss: 0.0022 - val_mae: 0.0392\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0033 - mae: 0.0525 - val_loss: 0.0022 - val_mae: 0.0402\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0031 - mae: 0.0481 - val_loss: 0.0020 - val_mae: 0.0346\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0032 - mae: 0.0517 - val_loss: 0.0021 - val_mae: 0.0354\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0031 - mae: 0.0500 - val_loss: 0.0019 - val_mae: 0.0350\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0032 - mae: 0.0525 - val_loss: 0.0023 - val_mae: 0.0433\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0032 - mae: 0.0516 - val_loss: 0.0020 - val_mae: 0.0352\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0030 - mae: 0.0496 - val_loss: 0.0019 - val_mae: 0.0323\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 1s 39ms/step - loss: 0.0030 - mae: 0.0488 - val_loss: 0.0021 - val_mae: 0.0363\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0031 - mae: 0.0496 - val_loss: 0.0019 - val_mae: 0.0335\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0029 - mae: 0.0482 - val_loss: 0.0025 - val_mae: 0.0455\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0029 - mae: 0.0468 - val_loss: 0.0018 - val_mae: 0.0313\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0028 - mae: 0.0461 - val_loss: 0.0021 - val_mae: 0.0350\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0030 - mae: 0.0495 - val_loss: 0.0019 - val_mae: 0.0305\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0030 - mae: 0.0493 - val_loss: 0.0019 - val_mae: 0.0312\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0027 - mae: 0.0436 - val_loss: 0.0023 - val_mae: 0.0448\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0028 - mae: 0.0458 - val_loss: 0.0018 - val_mae: 0.0314\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.0027 - mae: 0.0434 - val_loss: 0.0018 - val_mae: 0.0309\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0028 - mae: 0.0456 - val_loss: 0.0019 - val_mae: 0.0306\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0027 - mae: 0.0432 - val_loss: 0.0021 - val_mae: 0.0370\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0027 - mae: 0.0432 - val_loss: 0.0018 - val_mae: 0.0310\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0029 - mae: 0.0488 - val_loss: 0.0019 - val_mae: 0.0316\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0026 - mae: 0.0429 - val_loss: 0.0027 - val_mae: 0.0519\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0029 - mae: 0.0480 - val_loss: 0.0020 - val_mae: 0.0354\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0026 - mae: 0.0429 - val_loss: 0.0019 - val_mae: 0.0344\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0026 - mae: 0.0429 - val_loss: 0.0018 - val_mae: 0.0340\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0027 - mae: 0.0446 - val_loss: 0.0019 - val_mae: 0.0356\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0027 - mae: 0.0445 - val_loss: 0.0018 - val_mae: 0.0336\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0030 - mae: 0.0510 - val_loss: 0.0025 - val_mae: 0.0494\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0029 - mae: 0.0476 - val_loss: 0.0020 - val_mae: 0.0383\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0026 - mae: 0.0431 - val_loss: 0.0020 - val_mae: 0.0368\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0028 - mae: 0.0448 - val_loss: 0.0018 - val_mae: 0.0325\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0025 - mae: 0.0420 - val_loss: 0.0020 - val_mae: 0.0388\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0026 - mae: 0.0444 - val_loss: 0.0024 - val_mae: 0.0454\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0026 - mae: 0.0436 - val_loss: 0.0024 - val_mae: 0.0484\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0027 - mae: 0.0457 - val_loss: 0.0021 - val_mae: 0.0398\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0025 - mae: 0.0425 - val_loss: 0.0018 - val_mae: 0.0323\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0027 - mae: 0.0455 - val_loss: 0.0018 - val_mae: 0.0321\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0028 - mae: 0.0467 - val_loss: 0.0018 - val_mae: 0.0327\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0027 - mae: 0.0454 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0027 - mae: 0.0449 - val_loss: 0.0022 - val_mae: 0.0435\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0025 - mae: 0.0413 - val_loss: 0.0018 - val_mae: 0.0333\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0025 - mae: 0.0419 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0027 - mae: 0.0479 - val_loss: 0.0019 - val_mae: 0.0357\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0032 - mae: 0.0532 - val_loss: 0.0022 - val_mae: 0.0439\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0025 - mae: 0.0438 - val_loss: 0.0020 - val_mae: 0.0403\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0026 - mae: 0.0424 - val_loss: 0.0019 - val_mae: 0.0373\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0027 - mae: 0.0474 - val_loss: 0.0021 - val_mae: 0.0424\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0017 - val_mae: 0.0298\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0025 - mae: 0.0413 - val_loss: 0.0020 - val_mae: 0.0385\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0025 - mae: 0.0423 - val_loss: 0.0019 - val_mae: 0.0365\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0025 - mae: 0.0427 - val_loss: 0.0028 - val_mae: 0.0557\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0032 - mae: 0.0534 - val_loss: 0.0019 - val_mae: 0.0357\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 1s 39ms/step - loss: 0.0026 - mae: 0.0446 - val_loss: 0.0018 - val_mae: 0.0343\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 1s 38ms/step - loss: 0.0027 - mae: 0.0453 - val_loss: 0.0019 - val_mae: 0.0381\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 0.0018 - val_mae: 0.0345\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 1s 38ms/step - loss: 0.0025 - mae: 0.0426 - val_loss: 0.0018 - val_mae: 0.0322\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0024 - mae: 0.0407 - val_loss: 0.0019 - val_mae: 0.0371\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0025 - mae: 0.0424 - val_loss: 0.0019 - val_mae: 0.0369\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0026 - mae: 0.0452 - val_loss: 0.0017 - val_mae: 0.0317\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0024 - mae: 0.0401 - val_loss: 0.0017 - val_mae: 0.0334\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 1s 38ms/step - loss: 0.0026 - mae: 0.0438 - val_loss: 0.0017 - val_mae: 0.0333\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 0.0021 - val_mae: 0.0425\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0025 - mae: 0.0438 - val_loss: 0.0018 - val_mae: 0.0340\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.0026 - mae: 0.0452 - val_loss: 0.0018 - val_mae: 0.0355\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0025 - mae: 0.0430 - val_loss: 0.0027 - val_mae: 0.0532\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0027 - mae: 0.0455 - val_loss: 0.0017 - val_mae: 0.0316\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0024 - mae: 0.0407 - val_loss: 0.0017 - val_mae: 0.0335\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0024 - mae: 0.0402 - val_loss: 0.0017 - val_mae: 0.0337\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0024 - mae: 0.0424 - val_loss: 0.0018 - val_mae: 0.0343\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0023 - mae: 0.0403 - val_loss: 0.0017 - val_mae: 0.0336\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0024 - mae: 0.0415 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0025 - mae: 0.0439 - val_loss: 0.0018 - val_mae: 0.0348\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.0024 - mae: 0.0411 - val_loss: 0.0017 - val_mae: 0.0323\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.0024 - mae: 0.0406 - val_loss: 0.0018 - val_mae: 0.0366\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0026 - mae: 0.0429 - val_loss: 0.0018 - val_mae: 0.0353\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0026 - mae: 0.0447 - val_loss: 0.0017 - val_mae: 0.0340\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0025 - mae: 0.0418 - val_loss: 0.0020 - val_mae: 0.0414\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0025 - mae: 0.0440 - val_loss: 0.0022 - val_mae: 0.0438\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0023 - mae: 0.0396 - val_loss: 0.0019 - val_mae: 0.0377\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0024 - mae: 0.0411 - val_loss: 0.0018 - val_mae: 0.0345\n",
      "Epoch 104/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0025 - mae: 0.0442 - val_loss: 0.0018 - val_mae: 0.0353\n",
      "Epoch 105/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0024 - mae: 0.0422 - val_loss: 0.0019 - val_mae: 0.0382\n",
      "Epoch 106/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0024 - mae: 0.0427 - val_loss: 0.0019 - val_mae: 0.0362\n",
      "Epoch 107/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0025 - mae: 0.0444 - val_loss: 0.0018 - val_mae: 0.0340\n",
      "Epoch 108/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0023 - mae: 0.0395 - val_loss: 0.0017 - val_mae: 0.0347\n",
      "Epoch 109/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0024 - mae: 0.0422 - val_loss: 0.0026 - val_mae: 0.0513\n",
      "Epoch 110/500\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.0028 - mae: 0.0488 - val_loss: 0.0017 - val_mae: 0.0344\n",
      "Epoch 111/500\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.0026 - mae: 0.0448 - val_loss: 0.0018 - val_mae: 0.0349\n",
      "Epoch 112/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0024 - mae: 0.0410 - val_loss: 0.0017 - val_mae: 0.0314\n",
      "Epoch 113/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0024 - mae: 0.0423 - val_loss: 0.0017 - val_mae: 0.0307\n",
      "Epoch 114/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0024 - mae: 0.0415 - val_loss: 0.0018 - val_mae: 0.0349\n",
      "Epoch 115/500\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.0024 - mae: 0.0433 - val_loss: 0.0018 - val_mae: 0.0351\n",
      "Epoch 116/500\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.0024 - mae: 0.0417 - val_loss: 0.0019 - val_mae: 0.0373\n",
      "Epoch 117/500\n",
      "33/33 [==============================] - 1s 38ms/step - loss: 0.0023 - mae: 0.0398 - val_loss: 0.0017 - val_mae: 0.0343\n",
      "Epoch 118/500\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.0023 - mae: 0.0401 - val_loss: 0.0018 - val_mae: 0.0344\n",
      "Epoch 119/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0023 - mae: 0.0392 - val_loss: 0.0019 - val_mae: 0.0390\n",
      "Epoch 120/500\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 0.0023 - mae: 0.0400 - val_loss: 0.0019 - val_mae: 0.0371\n",
      "Epoch 121/500\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.0022 - mae: 0.0393 - val_loss: 0.0017 - val_mae: 0.0331\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0017 - mae: 0.0298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29806.658625602722"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – compiles, fits, and evaluates the model, like earlier\n",
    "fit_and_evaluate(deep_model, train_ds, valid_ds, learning_rate=0.01)  # return 30165"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0113e29-7b29-41b8-b595-c333a29049f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 多变量时间序列 Multivariate time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea6e5145-2abf-4beb-8f95-d7e243d7aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mulvar = df[[\"bus\", \"rail\"]] / 1e6  # use both bus & rail series as input\n",
    "df_mulvar[\"next_day_type\"] = df[\"day_type\"].shift(-1)  # we know tomorrow's type\n",
    "df_mulvar = pd.get_dummies(df_mulvar)  # one-hot encode the day type\n",
    "\n",
    "df_mulvar[\"next_day_type_A\"] = df_mulvar[\"next_day_type_A\"].astype(int)\n",
    "df_mulvar[\"next_day_type_U\"] = df_mulvar[\"next_day_type_U\"].astype(int)\n",
    "df_mulvar[\"next_day_type_W\"] = df_mulvar[\"next_day_type_W\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8468fd2-8c3c-4877-844b-33ba8ef7a1bc",
   "metadata": {},
   "source": [
    "数据处理解释：\n",
    "1. df_mulvar[\"next_day_type\"] = df[\"day_type\"].shift(-1): 创建一个新列 \"next_day_type\"，其中包含 \"day_type\" 列的明天的值。通过使用 shift(-1) 方法，将 \"day_type\" 向上偏移一天。\n",
    "\n",
    "2. df_mulvar = pd.get_dummies(df_mulvar): 对 \"day_type\" 进行独热编码，将其转换成三个二元特征列，分别代表 \"A\"、\"U\"、\"W\" 三个类别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e204c374-a143-4ed9-8a20-8c453906618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mulvar_train = df_mulvar[\"2016-01\":\"2018-12\"]\n",
    "mulvar_valid = df_mulvar[\"2019-01\":\"2019-05\"]\n",
    "mulvar_test = df_mulvar[\"2019-06\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b025d218-102c-4158-ac30-a8c1788c8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "train_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_train.to_numpy(),  # use all 5 columns as input\n",
    "    targets=mulvar_train[\"rail\"][seq_length:],  # forecast only the rail series\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_valid.to_numpy(),\n",
    "    targets=mulvar_valid[\"rail\"][seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e18583a5-5ac6-46af-8320-4efe1c1fdd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "mulvar_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20162929-4151-4c14-9cda-1ebe168c5d10",
   "metadata": {},
   "source": [
    "这段代码涉及到多变量时间序列数据的建模和训练，具体解释如下：\n",
    "\n",
    "1. `train_mulvar_ds`: 使用 `timeseries_dataset_from_array` 函数创建训练数据集，将 `mulvar_train.to_numpy()` 的所有 5 列作为输入。`targets` 参数指定了要预测的目标变量，这里是 \"rail\" 列，同时也指定了 `sequence_length`、`batch_size` 等参数。\n",
    "\n",
    "2. `valid_mulvar_ds`: 类似地，使用相同的函数创建验证数据集，`targets` 也是 \"rail\" 列。\n",
    "\n",
    "3. `mulvar_model`: 创建了一个顺序模型，包含一个 SimpleRNN 层和一个 Dense 层。SimpleRNN 层的 `input_shape=[None, 5]` 表示输入序列的长度可以是任意值，每个时间步有 5 个特征。\n",
    "\n",
    "这段代码的目的是利用多变量时间序列数据，以 \"bus\"、\"rail\" 等多个变量作为输入，预测下一个时间步的 \"rail\" 列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "029d1837-282b-4cf0-88c7-7d83b1f4ef58",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 2s 19ms/step - loss: 0.0360 - mae: 0.1767 - val_loss: 0.0016 - val_mae: 0.0413\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0033 - mae: 0.0630 - val_loss: 0.0012 - val_mae: 0.0353\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0016 - mae: 0.0388 - val_loss: 0.0011 - val_mae: 0.0366\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0016 - mae: 0.0410 - val_loss: 7.5276e-04 - val_mae: 0.0292\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0015 - mae: 0.0387 - val_loss: 0.0013 - val_mae: 0.0425\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0014 - mae: 0.0374 - val_loss: 8.9067e-04 - val_mae: 0.0331\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0014 - mae: 0.0366 - val_loss: 7.1662e-04 - val_mae: 0.0269\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0362 - val_loss: 7.9111e-04 - val_mae: 0.0308\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0350 - val_loss: 8.3587e-04 - val_mae: 0.0309\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0014 - mae: 0.0386 - val_loss: 7.1598e-04 - val_mae: 0.0278\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0350 - val_loss: 0.0012 - val_mae: 0.0401\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0355 - val_loss: 6.8701e-04 - val_mae: 0.0264\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0015 - mae: 0.0405 - val_loss: 0.0012 - val_mae: 0.0403\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0016 - mae: 0.0424 - val_loss: 6.7456e-04 - val_mae: 0.0255\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0014 - mae: 0.0381 - val_loss: 6.3998e-04 - val_mae: 0.0252\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0015 - mae: 0.0394 - val_loss: 0.0010 - val_mae: 0.0357\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0362 - val_loss: 9.1308e-04 - val_mae: 0.0338\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0013 - mae: 0.0364 - val_loss: 0.0012 - val_mae: 0.0402\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0355 - val_loss: 7.2739e-04 - val_mae: 0.0264\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0359 - val_loss: 0.0012 - val_mae: 0.0412\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0013 - mae: 0.0358 - val_loss: 6.3372e-04 - val_mae: 0.0240\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0012 - mae: 0.0332 - val_loss: 9.7111e-04 - val_mae: 0.0355\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0327 - val_loss: 6.2985e-04 - val_mae: 0.0251\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0012 - mae: 0.0336 - val_loss: 6.3473e-04 - val_mae: 0.0243\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0012 - mae: 0.0336 - val_loss: 6.1789e-04 - val_mae: 0.0255\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0011 - mae: 0.0331 - val_loss: 6.4654e-04 - val_mae: 0.0243\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0317 - val_loss: 0.0016 - val_mae: 0.0483\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0012 - mae: 0.0343 - val_loss: 7.7259e-04 - val_mae: 0.0283\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0331 - val_loss: 7.7753e-04 - val_mae: 0.0289\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0013 - mae: 0.0368 - val_loss: 8.6769e-04 - val_mae: 0.0280\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0366 - val_loss: 7.3782e-04 - val_mae: 0.0276\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0012 - mae: 0.0353 - val_loss: 8.9541e-04 - val_mae: 0.0330\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0329 - val_loss: 7.4212e-04 - val_mae: 0.0277\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0012 - mae: 0.0342 - val_loss: 8.5928e-04 - val_mae: 0.0283\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0012 - mae: 0.0331 - val_loss: 6.5322e-04 - val_mae: 0.0258\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0011 - mae: 0.0313 - val_loss: 6.9468e-04 - val_mae: 0.0283\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0011 - mae: 0.0334 - val_loss: 6.0190e-04 - val_mae: 0.0249\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0352 - val_loss: 8.5881e-04 - val_mae: 0.0325\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0010 - mae: 0.0307 - val_loss: 8.8777e-04 - val_mae: 0.0334\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0012 - mae: 0.0351 - val_loss: 0.0012 - val_mae: 0.0365\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0012 - mae: 0.0335 - val_loss: 9.8347e-04 - val_mae: 0.0339\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0320 - val_loss: 8.0794e-04 - val_mae: 0.0314\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0333 - val_loss: 7.1988e-04 - val_mae: 0.0287\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0013 - mae: 0.0375 - val_loss: 0.0011 - val_mae: 0.0357\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0328 - val_loss: 7.2593e-04 - val_mae: 0.0282\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0319 - val_loss: 6.7666e-04 - val_mae: 0.0264\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0010 - mae: 0.0301 - val_loss: 8.2550e-04 - val_mae: 0.0285\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0330 - val_loss: 7.2183e-04 - val_mae: 0.0272\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0010 - mae: 0.0313 - val_loss: 6.1866e-04 - val_mae: 0.0246\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0010 - mae: 0.0309 - val_loss: 7.3012e-04 - val_mae: 0.0279\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0011 - mae: 0.0314 - val_loss: 7.9028e-04 - val_mae: 0.0294\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0011 - mae: 0.0321 - val_loss: 0.0016 - val_mae: 0.0483\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0012 - mae: 0.0344 - val_loss: 8.9138e-04 - val_mae: 0.0316\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0014 - mae: 0.0378 - val_loss: 7.0643e-04 - val_mae: 0.0250\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0010 - mae: 0.0308 - val_loss: 0.0013 - val_mae: 0.0435\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0011 - mae: 0.0316 - val_loss: 5.9867e-04 - val_mae: 0.0239\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0333 - val_loss: 0.0013 - val_mae: 0.0429\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0328 - val_loss: 5.9934e-04 - val_mae: 0.0238\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0010 - mae: 0.0311 - val_loss: 0.0017 - val_mae: 0.0520\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0371 - val_loss: 8.4870e-04 - val_mae: 0.0318\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0010 - mae: 0.0309 - val_loss: 6.3262e-04 - val_mae: 0.0236\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0010 - mae: 0.0307 - val_loss: 0.0011 - val_mae: 0.0390\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0010 - mae: 0.0305 - val_loss: 6.3868e-04 - val_mae: 0.0251\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0011 - mae: 0.0320 - val_loss: 6.2607e-04 - val_mae: 0.0256\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0011 - mae: 0.0313 - val_loss: 6.7419e-04 - val_mae: 0.0246\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0010 - mae: 0.0306 - val_loss: 5.6027e-04 - val_mae: 0.0229\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0315 - val_loss: 7.1625e-04 - val_mae: 0.0283\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 9.9627e-04 - mae: 0.0304 - val_loss: 6.6871e-04 - val_mae: 0.0264\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 9.8588e-04 - mae: 0.0297 - val_loss: 7.4060e-04 - val_mae: 0.0276\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0010 - mae: 0.0313 - val_loss: 0.0011 - val_mae: 0.0386\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0010 - mae: 0.0305 - val_loss: 7.5988e-04 - val_mae: 0.0290\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0010 - mae: 0.0317 - val_loss: 9.3312e-04 - val_mae: 0.0292\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0321 - val_loss: 7.8324e-04 - val_mae: 0.0291\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0010 - mae: 0.0314 - val_loss: 9.3916e-04 - val_mae: 0.0333\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0010 - mae: 0.0310 - val_loss: 6.5133e-04 - val_mae: 0.0241\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 9.7777e-04 - mae: 0.0296 - val_loss: 8.3541e-04 - val_mae: 0.0290\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0011 - mae: 0.0331 - val_loss: 6.2770e-04 - val_mae: 0.0263\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0010 - mae: 0.0306 - val_loss: 9.2227e-04 - val_mae: 0.0319\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0339 - val_loss: 0.0010 - val_mae: 0.0322\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0010 - mae: 0.0307 - val_loss: 6.5109e-04 - val_mae: 0.0253\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0331 - val_loss: 6.5525e-04 - val_mae: 0.0253\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 9.5754e-04 - mae: 0.0294 - val_loss: 6.9351e-04 - val_mae: 0.0267\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0316 - val_loss: 9.3814e-04 - val_mae: 0.0306\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 9.9065e-04 - mae: 0.0302 - val_loss: 6.1657e-04 - val_mae: 0.0241\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 9.5741e-04 - mae: 0.0290 - val_loss: 6.4636e-04 - val_mae: 0.0241\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 9.3764e-04 - mae: 0.0284 - val_loss: 7.5331e-04 - val_mae: 0.0270\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 9.4275e-04 - mae: 0.0290 - val_loss: 9.9876e-04 - val_mae: 0.0361\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 9.5892e-04 - mae: 0.0298 - val_loss: 6.7184e-04 - val_mae: 0.0245\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 9.7359e-04 - mae: 0.0300 - val_loss: 6.1252e-04 - val_mae: 0.0246\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0010 - mae: 0.0305 - val_loss: 7.4206e-04 - val_mae: 0.0271\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 9.1384e-04 - mae: 0.0285 - val_loss: 6.1550e-04 - val_mae: 0.0240\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 9.2175e-04 - mae: 0.0286 - val_loss: 7.6621e-04 - val_mae: 0.0286\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 9.5910e-04 - mae: 0.0301 - val_loss: 8.3740e-04 - val_mae: 0.0308\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0010 - mae: 0.0315 - val_loss: 6.3759e-04 - val_mae: 0.0253\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 9.8296e-04 - mae: 0.0303 - val_loss: 7.5771e-04 - val_mae: 0.0287\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0010 - mae: 0.0311 - val_loss: 9.4335e-04 - val_mae: 0.0340\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0010 - mae: 0.0314 - val_loss: 0.0017 - val_mae: 0.0511\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 9.8521e-04 - mae: 0.0308 - val_loss: 6.4457e-04 - val_mae: 0.0243\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0010 - mae: 0.0306 - val_loss: 6.0949e-04 - val_mae: 0.0245\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0011 - mae: 0.0336 - val_loss: 9.6021e-04 - val_mae: 0.0329\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0011 - mae: 0.0339 - val_loss: 6.8201e-04 - val_mae: 0.0269\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 9.9115e-04 - mae: 0.0300 - val_loss: 9.2619e-04 - val_mae: 0.0314\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 9.2158e-04 - mae: 0.0280 - val_loss: 9.5157e-04 - val_mae: 0.0325\n",
      "Epoch 104/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0010 - mae: 0.0318 - val_loss: 6.5235e-04 - val_mae: 0.0259\n",
      "Epoch 105/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0010 - mae: 0.0325 - val_loss: 8.5419e-04 - val_mae: 0.0314\n",
      "Epoch 106/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 9.1153e-04 - mae: 0.0283 - val_loss: 7.8694e-04 - val_mae: 0.0272\n",
      "Epoch 107/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 8.9517e-04 - mae: 0.0279 - val_loss: 6.2729e-04 - val_mae: 0.0244\n",
      "Epoch 108/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 9.4058e-04 - mae: 0.0293 - val_loss: 6.3473e-04 - val_mae: 0.0249\n",
      "Epoch 109/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 9.2073e-04 - mae: 0.0287 - val_loss: 6.9867e-04 - val_mae: 0.0256\n",
      "Epoch 110/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 9.3988e-04 - mae: 0.0293 - val_loss: 7.9483e-04 - val_mae: 0.0316\n",
      "Epoch 111/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0011 - mae: 0.0329 - val_loss: 5.9320e-04 - val_mae: 0.0243\n",
      "Epoch 112/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0010 - mae: 0.0317 - val_loss: 5.7645e-04 - val_mae: 0.0232\n",
      "Epoch 113/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0328 - val_loss: 0.0011 - val_mae: 0.0350\n",
      "Epoch 114/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 9.6921e-04 - mae: 0.0301 - val_loss: 5.8634e-04 - val_mae: 0.0244\n",
      "Epoch 115/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 9.4145e-04 - mae: 0.0289 - val_loss: 8.2966e-04 - val_mae: 0.0281\n",
      "Epoch 116/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 9.2371e-04 - mae: 0.0289 - val_loss: 7.2067e-04 - val_mae: 0.0272\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 5.6027e-04 - mae: 0.0229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22907.99468755722"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_and_evaluate(mulvar_model, train_mulvar_ds, valid_mulvar_ds, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b5717-ec8d-4e6b-b1a9-56ae06cf94a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 多任务 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7da63e7-6d9d-4327-9f3a-72aedb52cea8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 2s 23ms/step - loss: 0.0744 - mae: 0.2664 - val_loss: 0.0078 - val_mae: 0.1089\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0041 - mae: 0.0657 - val_loss: 0.0019 - val_mae: 0.0494\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0025 - mae: 0.0481 - val_loss: 0.0011 - val_mae: 0.0348\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0022 - mae: 0.0454 - val_loss: 0.0019 - val_mae: 0.0508\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0021 - mae: 0.0445 - val_loss: 0.0012 - val_mae: 0.0372\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0020 - mae: 0.0427 - val_loss: 0.0010 - val_mae: 0.0341\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0019 - mae: 0.0418 - val_loss: 0.0010 - val_mae: 0.0351\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0018 - mae: 0.0410 - val_loss: 0.0012 - val_mae: 0.0384\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0017 - mae: 0.0405 - val_loss: 0.0011 - val_mae: 0.0364\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0017 - mae: 0.0397 - val_loss: 9.4073e-04 - val_mae: 0.0331\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0016 - mae: 0.0396 - val_loss: 9.3438e-04 - val_mae: 0.0331\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0016 - mae: 0.0386 - val_loss: 7.9555e-04 - val_mae: 0.0297\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0015 - mae: 0.0382 - val_loss: 7.8288e-04 - val_mae: 0.0293\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0015 - mae: 0.0377 - val_loss: 9.7321e-04 - val_mae: 0.0341\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0015 - mae: 0.0373 - val_loss: 0.0011 - val_mae: 0.0370\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0014 - mae: 0.0366 - val_loss: 6.8429e-04 - val_mae: 0.0267\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 8.2916e-04 - val_mae: 0.0307\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0014 - mae: 0.0364 - val_loss: 7.8600e-04 - val_mae: 0.0296\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0013 - mae: 0.0359 - val_loss: 6.8530e-04 - val_mae: 0.0263\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0013 - mae: 0.0361 - val_loss: 7.0246e-04 - val_mae: 0.0277\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0013 - mae: 0.0354 - val_loss: 7.7890e-04 - val_mae: 0.0292\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0352 - val_loss: 8.7355e-04 - val_mae: 0.0320\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0352 - val_loss: 7.9031e-04 - val_mae: 0.0297\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0354 - val_loss: 8.1226e-04 - val_mae: 0.0304\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0012 - mae: 0.0346 - val_loss: 9.2547e-04 - val_mae: 0.0336\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0013 - mae: 0.0349 - val_loss: 7.5523e-04 - val_mae: 0.0288\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0012 - mae: 0.0346 - val_loss: 7.2790e-04 - val_mae: 0.0282\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0012 - mae: 0.0348 - val_loss: 7.1011e-04 - val_mae: 0.0276\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0013 - mae: 0.0357 - val_loss: 6.7669e-04 - val_mae: 0.0267\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0012 - mae: 0.0342 - val_loss: 6.8752e-04 - val_mae: 0.0268\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0012 - mae: 0.0340 - val_loss: 8.7747e-04 - val_mae: 0.0322\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0012 - mae: 0.0339 - val_loss: 6.6332e-04 - val_mae: 0.0261\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0012 - mae: 0.0340 - val_loss: 6.9392e-04 - val_mae: 0.0270\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0012 - mae: 0.0334 - val_loss: 7.3993e-04 - val_mae: 0.0285\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0012 - mae: 0.0333 - val_loss: 7.8921e-04 - val_mae: 0.0299\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0012 - mae: 0.0347 - val_loss: 7.5616e-04 - val_mae: 0.0289\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0012 - mae: 0.0342 - val_loss: 6.6085e-04 - val_mae: 0.0262\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0333 - val_loss: 6.7640e-04 - val_mae: 0.0266\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0329 - val_loss: 7.5554e-04 - val_mae: 0.0290\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0012 - mae: 0.0333 - val_loss: 8.2400e-04 - val_mae: 0.0308\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0328 - val_loss: 7.3675e-04 - val_mae: 0.0287\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0330 - val_loss: 7.7393e-04 - val_mae: 0.0297\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0330 - val_loss: 8.3271e-04 - val_mae: 0.0313\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0011 - mae: 0.0331 - val_loss: 7.0316e-04 - val_mae: 0.0275\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0011 - mae: 0.0333 - val_loss: 7.2936e-04 - val_mae: 0.0283\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0329 - val_loss: 7.0294e-04 - val_mae: 0.0277\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0327 - val_loss: 7.2659e-04 - val_mae: 0.0284\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0011 - mae: 0.0329 - val_loss: 6.6682e-04 - val_mae: 0.0265\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0327 - val_loss: 7.1163e-04 - val_mae: 0.0272\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0325 - val_loss: 9.0974e-04 - val_mae: 0.0334\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0012 - mae: 0.0338 - val_loss: 7.8253e-04 - val_mae: 0.0301\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0332 - val_loss: 7.3406e-04 - val_mae: 0.0281\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0328 - val_loss: 7.7983e-04 - val_mae: 0.0297\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0012 - mae: 0.0341 - val_loss: 6.5817e-04 - val_mae: 0.0261\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0011 - mae: 0.0321 - val_loss: 7.9080e-04 - val_mae: 0.0302\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0322 - val_loss: 6.8914e-04 - val_mae: 0.0272\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0320 - val_loss: 7.3121e-04 - val_mae: 0.0285\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0323 - val_loss: 6.5715e-04 - val_mae: 0.0264\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0319 - val_loss: 7.0237e-04 - val_mae: 0.0274\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0011 - mae: 0.0322 - val_loss: 6.8434e-04 - val_mae: 0.0269\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0317 - val_loss: 6.9754e-04 - val_mae: 0.0274\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0318 - val_loss: 7.1080e-04 - val_mae: 0.0281\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0325 - val_loss: 7.0976e-04 - val_mae: 0.0277\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0324 - val_loss: 7.5185e-04 - val_mae: 0.0290\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0011 - mae: 0.0329 - val_loss: 6.9503e-04 - val_mae: 0.0267\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0326 - val_loss: 7.1388e-04 - val_mae: 0.0278\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0011 - mae: 0.0319 - val_loss: 6.8300e-04 - val_mae: 0.0272\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0316 - val_loss: 7.1021e-04 - val_mae: 0.0275\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0319 - val_loss: 7.3645e-04 - val_mae: 0.0276\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0011 - mae: 0.0321 - val_loss: 7.1648e-04 - val_mae: 0.0281\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0011 - mae: 0.0318 - val_loss: 6.8443e-04 - val_mae: 0.0269\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0011 - mae: 0.0317 - val_loss: 7.4605e-04 - val_mae: 0.0288\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0010 - mae: 0.0316 - val_loss: 7.0176e-04 - val_mae: 0.0270\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0010 - mae: 0.0314 - val_loss: 6.9932e-04 - val_mae: 0.0269\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0011 - mae: 0.0320 - val_loss: 6.8289e-04 - val_mae: 0.0273\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0010 - mae: 0.0316 - val_loss: 6.7312e-04 - val_mae: 0.0265\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0010 - mae: 0.0317 - val_loss: 6.8230e-04 - val_mae: 0.0267\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0010 - mae: 0.0313 - val_loss: 7.2281e-04 - val_mae: 0.0279\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0010 - mae: 0.0316 - val_loss: 7.1090e-04 - val_mae: 0.0277\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0010 - mae: 0.0316 - val_loss: 6.9675e-04 - val_mae: 0.0274\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0010 - mae: 0.0314 - val_loss: 7.3661e-04 - val_mae: 0.0287\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0010 - mae: 0.0318 - val_loss: 6.5952e-04 - val_mae: 0.0265\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 6.6332e-04 - mae: 0.0261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26092.7751660347"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – build and train a multitask RNN that forecasts both bus and rail\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "seq_length = 56\n",
    "train_multask_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_train.to_numpy(),\n",
    "    targets=mulvar_train[[\"bus\", \"rail\"]][seq_length:],  # 2 targets per day\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "valid_multask_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_valid.to_numpy(),\n",
    "    targets=mulvar_valid[[\"bus\", \"rail\"]][seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "multask_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "fit_and_evaluate(multask_model, train_multask_ds, valid_multask_ds,\n",
    "                 learning_rate=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f9887-abea-4a93-a263-a29d6f46e8d9",
   "metadata": {},
   "source": [
    "26092  \n",
    "这段代码的目的是构建一个可以同时预测 \"bus\" 和 \"rail\" 列的多任务模型，并使用多任务数据集进行训练和评估。\n",
    "\n",
    "1. train_multask_ds: 使用 timeseries_dataset_from_array 函数创建多任务训练数据集。targets 参数指定了要预测的目标变量，这里是 \"bus\" 和 \"rail\" 列，每天有两个目标。\n",
    "\n",
    "2. valid_multask_ds: 类似地，使用相同的函数创建验证数据集。\n",
    "\n",
    "3. multask_model: 创建了一个顺序模型，包含一个 SimpleRNN 层和一个 Dense 层。SimpleRNN 层的 input_shape=[None, 5] 表示输入序列的长度可以是任意值，每个时间步有 5 个特征。Dense 层有 2 个神经元，因为我们有两个目标变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d1a3050-3946-40fd-9b02-bee4d3bb0899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43441.63157894738"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluates the naive forecasts for bus\n",
    "bus_naive = mulvar_valid[\"bus\"].shift(7)[seq_length:]\n",
    "bus_target = mulvar_valid[\"bus\"][seq_length:]\n",
    "(bus_target - bus_naive).abs().mean() * 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb745e1d-d1f1-465b-a295-64205d0908c6",
   "metadata": {},
   "source": [
    "这段代码计算了\"bus\"列的简单滞后（naive）预测的平均绝对误差（Mean Absolute Error，MAE）。具体解释如下：\n",
    "\n",
    "1. bus_naive = mulvar_valid[\"bus\"].shift(7)[seq_length:]: 创建了一个简单滞后（naive）预测的 \"bus\" 列。通过使用 shift(7) 将时间序列向后移动 7 天，即使用过去一周的数据作为预测。\n",
    "\n",
    "2. bus_target = mulvar_valid[\"bus\"][seq_length:]: 选取验证集中 \"bus\" 列的真实值，确保从同一时间步开始，保持与 bus_naive 对齐。\n",
    "\n",
    "3. (bus_target - bus_naive).abs().mean() * 1e6: 计算滞后预测的平均绝对误差。首先，通过 (bus_target - bus_naive) 得到每个时间步的预测误差，然后使用 .abs() 计算绝对值，最后使用 .mean() 计算平均值。\n",
    "\n",
    "这个操作的目的是评估在使用简单滞后预测的情况下，模型在 \"bus\" 列上的表现。如果误差很小，说明简单滞后方法在这个时间序列上可能是有效的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd50eb76-75aa-40fc-91ae-3c88b6a3f6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step\n",
      "bus 26630\n",
      "rail 25554\n"
     ]
    }
   ],
   "source": [
    "# evaluates the multitask RNN's forecasts both bus and rail\n",
    "Y_preds_valid = multask_model.predict(valid_multask_ds)\n",
    "for idx, name in enumerate([\"bus\", \"rail\"]):\n",
    "    mae = 1e6 * tf.keras.metrics.mean_absolute_error(\n",
    "        mulvar_valid[name][seq_length:], Y_preds_valid[:, idx])\n",
    "    print(name, int(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98d583-ae13-4b98-84c3-5f56319eb0ec",
   "metadata": {},
   "source": [
    "评估多任务 RNN 模型对 \"bus\" 和 \"rail\" 列的预测性能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e8d9e-5d0d-47cd-a2dd-018495b690a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Forecasting Several Steps Ahead \n",
    "使用单变量RNN模型进行未来时间步预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a57a6a48-7cce-4408-b25d-0a0782ed5d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = rail_valid.to_numpy()[np.newaxis, :seq_length, np.newaxis]\n",
    "for step_ahead in range(14):\n",
    "    y_pred_one = univar_model.predict(X)\n",
    "    X = np.concatenate([X, y_pred_one.reshape(1, 1, 1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a201594a-9528-4f88-ac1b-448439754da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The forecasts start on 2019-02-26, as it is the 57th day of 2019, and they end on 2019-03-31. That's 14 days in total.\n",
    "Y_pred = pd.Series(X[0, -14:, 0], index=pd.date_range(\"2019-02-26\", \"2019-03-11\"))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 3.5))\n",
    "(rail_valid * 1e6)[\"2019-02-01\":\"2019-03-11\"].plot(label=\"True\", marker=\".\", ax=ax)\n",
    "(Y_pred * 1e6).plot(label=\"Predictions\", grid=True, marker=\"x\", color=\"r\", ax=ax)\n",
    "ax.vlines(\"2019-02-25\", 0, 1e6, color=\"k\", linestyle=\"--\", label=\"Today\")\n",
    "ax.set_ylim([200_000, 800_000])\n",
    "plt.legend(loc=\"center left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87ea249-e903-40ff-b4b8-01d390d90ea1",
   "metadata": {},
   "source": [
    "上述代码通过单变量 RNN 模型对未来时间步进行预测，并将预测结果与真实值进行对比。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad309d80-3c70-4902-9d27-c3b8460439a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 使用多变量时间序列数据进行未来时间步预测\n",
    "Now let's create an RNN that predicts all 14 next values at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6aceed41-ef71-4c5c-b531-acbe071e22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "def split_inputs_and_targets(mulvar_series, ahead=14, target_col=1):\n",
    "    return mulvar_series[:, :-ahead], mulvar_series[:, -ahead:, target_col]\n",
    "\n",
    "ahead_train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_train.to_numpy(),\n",
    "    targets=None,\n",
    "    sequence_length=seq_length + 14,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ").map(split_inputs_and_targets)\n",
    "\n",
    "ahead_valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_valid.to_numpy(),\n",
    "    targets=None,\n",
    "    sequence_length=seq_length + 14,\n",
    "    batch_size=32\n",
    ").map(split_inputs_and_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7602b6cb-2b35-41cc-8384-64ba577da31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "ahead_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df2895bd-63bf-4b0d-b58e-948f987ae018",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 2s 21ms/step - loss: 0.0767 - mae: 0.2918 - val_loss: 0.0279 - val_mae: 0.1862\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0214 - mae: 0.1646 - val_loss: 0.0163 - val_mae: 0.1380\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0153 - mae: 0.1385 - val_loss: 0.0121 - val_mae: 0.1210\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0125 - mae: 0.1243 - val_loss: 0.0099 - val_mae: 0.1088\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0107 - mae: 0.1139 - val_loss: 0.0086 - val_mae: 0.1014\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0071 - val_mae: 0.0921\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0086 - mae: 0.0996 - val_loss: 0.0063 - val_mae: 0.0872\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0079 - mae: 0.0955 - val_loss: 0.0056 - val_mae: 0.0826\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0074 - mae: 0.0907 - val_loss: 0.0052 - val_mae: 0.0793\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0070 - mae: 0.0873 - val_loss: 0.0049 - val_mae: 0.0766\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0066 - mae: 0.0839 - val_loss: 0.0044 - val_mae: 0.0730\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0063 - mae: 0.0815 - val_loss: 0.0040 - val_mae: 0.0701\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0061 - mae: 0.0798 - val_loss: 0.0040 - val_mae: 0.0698\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0058 - mae: 0.0771 - val_loss: 0.0036 - val_mae: 0.0663\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0057 - mae: 0.0753 - val_loss: 0.0034 - val_mae: 0.0641\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0055 - mae: 0.0735 - val_loss: 0.0032 - val_mae: 0.0624\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0053 - mae: 0.0719 - val_loss: 0.0032 - val_mae: 0.0628\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0052 - mae: 0.0706 - val_loss: 0.0030 - val_mae: 0.0604\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0051 - mae: 0.0695 - val_loss: 0.0028 - val_mae: 0.0585\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0050 - mae: 0.0680 - val_loss: 0.0028 - val_mae: 0.0588\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0049 - mae: 0.0670 - val_loss: 0.0026 - val_mae: 0.0559\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0048 - mae: 0.0661 - val_loss: 0.0026 - val_mae: 0.0561\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0653 - val_loss: 0.0025 - val_mae: 0.0546\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0046 - mae: 0.0646 - val_loss: 0.0026 - val_mae: 0.0564\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0046 - mae: 0.0639 - val_loss: 0.0024 - val_mae: 0.0537\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0630 - val_loss: 0.0023 - val_mae: 0.0524\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0045 - mae: 0.0625 - val_loss: 0.0024 - val_mae: 0.0531\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0618 - val_loss: 0.0022 - val_mae: 0.0503\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0611 - val_loss: 0.0022 - val_mae: 0.0502\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0044 - mae: 0.0609 - val_loss: 0.0021 - val_mae: 0.0488\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0043 - mae: 0.0607 - val_loss: 0.0021 - val_mae: 0.0496\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0043 - mae: 0.0597 - val_loss: 0.0021 - val_mae: 0.0487\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0594 - val_loss: 0.0020 - val_mae: 0.0472\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0042 - mae: 0.0589 - val_loss: 0.0020 - val_mae: 0.0478\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0042 - mae: 0.0585 - val_loss: 0.0021 - val_mae: 0.0485\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0582 - val_loss: 0.0020 - val_mae: 0.0477\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0041 - mae: 0.0578 - val_loss: 0.0019 - val_mae: 0.0463\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0041 - mae: 0.0576 - val_loss: 0.0020 - val_mae: 0.0482\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0041 - mae: 0.0575 - val_loss: 0.0019 - val_mae: 0.0466\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0040 - mae: 0.0569 - val_loss: 0.0020 - val_mae: 0.0471\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0040 - mae: 0.0566 - val_loss: 0.0019 - val_mae: 0.0458\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0040 - mae: 0.0564 - val_loss: 0.0019 - val_mae: 0.0456\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0040 - mae: 0.0562 - val_loss: 0.0017 - val_mae: 0.0431\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0040 - mae: 0.0565 - val_loss: 0.0020 - val_mae: 0.0477\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0039 - mae: 0.0559 - val_loss: 0.0019 - val_mae: 0.0458\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0039 - mae: 0.0555 - val_loss: 0.0019 - val_mae: 0.0454\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0039 - mae: 0.0553 - val_loss: 0.0019 - val_mae: 0.0449\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0039 - mae: 0.0548 - val_loss: 0.0017 - val_mae: 0.0434\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0039 - mae: 0.0548 - val_loss: 0.0017 - val_mae: 0.0428\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0038 - mae: 0.0545 - val_loss: 0.0017 - val_mae: 0.0424\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0038 - mae: 0.0544 - val_loss: 0.0017 - val_mae: 0.0427\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0038 - mae: 0.0543 - val_loss: 0.0018 - val_mae: 0.0434\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0038 - mae: 0.0537 - val_loss: 0.0016 - val_mae: 0.0409\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0038 - mae: 0.0546 - val_loss: 0.0018 - val_mae: 0.0433\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0038 - mae: 0.0536 - val_loss: 0.0017 - val_mae: 0.0423\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0038 - mae: 0.0535 - val_loss: 0.0018 - val_mae: 0.0435\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0038 - mae: 0.0537 - val_loss: 0.0017 - val_mae: 0.0428\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0037 - mae: 0.0532 - val_loss: 0.0017 - val_mae: 0.0428\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0037 - mae: 0.0531 - val_loss: 0.0017 - val_mae: 0.0422\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0037 - mae: 0.0528 - val_loss: 0.0015 - val_mae: 0.0392\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0037 - mae: 0.0525 - val_loss: 0.0016 - val_mae: 0.0398\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0037 - mae: 0.0527 - val_loss: 0.0017 - val_mae: 0.0425\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0037 - mae: 0.0523 - val_loss: 0.0017 - val_mae: 0.0414\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0037 - mae: 0.0521 - val_loss: 0.0017 - val_mae: 0.0422\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0037 - mae: 0.0523 - val_loss: 0.0017 - val_mae: 0.0419\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0036 - mae: 0.0520 - val_loss: 0.0015 - val_mae: 0.0391\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0036 - mae: 0.0529 - val_loss: 0.0017 - val_mae: 0.0423\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0036 - mae: 0.0521 - val_loss: 0.0017 - val_mae: 0.0415\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0036 - mae: 0.0519 - val_loss: 0.0016 - val_mae: 0.0405\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0036 - mae: 0.0514 - val_loss: 0.0016 - val_mae: 0.0401\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0036 - mae: 0.0516 - val_loss: 0.0017 - val_mae: 0.0423\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0036 - mae: 0.0514 - val_loss: 0.0016 - val_mae: 0.0394\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0036 - mae: 0.0512 - val_loss: 0.0015 - val_mae: 0.0394\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0035 - mae: 0.0510 - val_loss: 0.0017 - val_mae: 0.0416\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0035 - mae: 0.0510 - val_loss: 0.0017 - val_mae: 0.0409\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0035 - mae: 0.0507 - val_loss: 0.0018 - val_mae: 0.0424\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0035 - mae: 0.0508 - val_loss: 0.0016 - val_mae: 0.0396\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0035 - mae: 0.0506 - val_loss: 0.0016 - val_mae: 0.0401\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0035 - mae: 0.0507 - val_loss: 0.0016 - val_mae: 0.0402\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0035 - mae: 0.0504 - val_loss: 0.0017 - val_mae: 0.0414\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0035 - mae: 0.0503 - val_loss: 0.0015 - val_mae: 0.0373\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0035 - mae: 0.0507 - val_loss: 0.0015 - val_mae: 0.0379\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0035 - mae: 0.0501 - val_loss: 0.0015 - val_mae: 0.0380\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0035 - mae: 0.0502 - val_loss: 0.0016 - val_mae: 0.0401\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0035 - mae: 0.0499 - val_loss: 0.0015 - val_mae: 0.0386\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0035 - mae: 0.0502 - val_loss: 0.0014 - val_mae: 0.0370\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0501 - val_loss: 0.0016 - val_mae: 0.0402\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0497 - val_loss: 0.0015 - val_mae: 0.0375\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0034 - mae: 0.0496 - val_loss: 0.0015 - val_mae: 0.0375\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0497 - val_loss: 0.0014 - val_mae: 0.0371\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0034 - mae: 0.0496 - val_loss: 0.0015 - val_mae: 0.0371\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0494 - val_loss: 0.0016 - val_mae: 0.0396\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0492 - val_loss: 0.0014 - val_mae: 0.0363\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0034 - mae: 0.0495 - val_loss: 0.0014 - val_mae: 0.0370\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0034 - mae: 0.0493 - val_loss: 0.0014 - val_mae: 0.0368\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0034 - mae: 0.0489 - val_loss: 0.0015 - val_mae: 0.0373\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0490 - val_loss: 0.0015 - val_mae: 0.0381\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0491 - val_loss: 0.0014 - val_mae: 0.0363\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0033 - mae: 0.0487 - val_loss: 0.0015 - val_mae: 0.0383\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0033 - mae: 0.0487 - val_loss: 0.0014 - val_mae: 0.0362\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0033 - mae: 0.0486 - val_loss: 0.0015 - val_mae: 0.0375\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0033 - mae: 0.0490 - val_loss: 0.0017 - val_mae: 0.0409\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0492 - val_loss: 0.0014 - val_mae: 0.0357\n",
      "Epoch 104/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0033 - mae: 0.0492 - val_loss: 0.0014 - val_mae: 0.0360\n",
      "Epoch 105/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0483 - val_loss: 0.0015 - val_mae: 0.0372\n",
      "Epoch 106/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0033 - mae: 0.0482 - val_loss: 0.0014 - val_mae: 0.0356\n",
      "Epoch 107/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0483 - val_loss: 0.0015 - val_mae: 0.0376\n",
      "Epoch 108/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0484 - val_loss: 0.0014 - val_mae: 0.0361\n",
      "Epoch 109/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0033 - mae: 0.0482 - val_loss: 0.0014 - val_mae: 0.0357\n",
      "Epoch 110/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0033 - mae: 0.0477 - val_loss: 0.0014 - val_mae: 0.0356\n",
      "Epoch 111/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0033 - mae: 0.0486 - val_loss: 0.0014 - val_mae: 0.0360\n",
      "Epoch 112/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0033 - mae: 0.0482 - val_loss: 0.0014 - val_mae: 0.0354\n",
      "Epoch 113/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0033 - mae: 0.0480 - val_loss: 0.0014 - val_mae: 0.0356\n",
      "Epoch 114/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0033 - mae: 0.0480 - val_loss: 0.0014 - val_mae: 0.0363\n",
      "Epoch 115/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0033 - mae: 0.0489 - val_loss: 0.0014 - val_mae: 0.0353\n",
      "Epoch 116/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0032 - mae: 0.0474 - val_loss: 0.0013 - val_mae: 0.0349\n",
      "Epoch 117/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0033 - mae: 0.0483 - val_loss: 0.0014 - val_mae: 0.0359\n",
      "Epoch 118/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0033 - mae: 0.0483 - val_loss: 0.0014 - val_mae: 0.0358\n",
      "Epoch 119/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0032 - mae: 0.0474 - val_loss: 0.0014 - val_mae: 0.0354\n",
      "Epoch 120/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0014 - val_mae: 0.0356\n",
      "Epoch 121/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0480 - val_loss: 0.0015 - val_mae: 0.0379\n",
      "Epoch 122/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0032 - mae: 0.0475 - val_loss: 0.0014 - val_mae: 0.0360\n",
      "Epoch 123/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0477 - val_loss: 0.0014 - val_mae: 0.0351\n",
      "Epoch 124/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0032 - mae: 0.0473 - val_loss: 0.0014 - val_mae: 0.0365\n",
      "Epoch 125/500\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 0.0032 - mae: 0.0473 - val_loss: 0.0014 - val_mae: 0.0355\n",
      "Epoch 126/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0477 - val_loss: 0.0013 - val_mae: 0.0346\n",
      "Epoch 127/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0032 - mae: 0.0471 - val_loss: 0.0014 - val_mae: 0.0350\n",
      "Epoch 128/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0032 - mae: 0.0477 - val_loss: 0.0016 - val_mae: 0.0387\n",
      "Epoch 129/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0032 - mae: 0.0474 - val_loss: 0.0014 - val_mae: 0.0350\n",
      "Epoch 130/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0032 - mae: 0.0475 - val_loss: 0.0014 - val_mae: 0.0351\n",
      "Epoch 131/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0032 - mae: 0.0468 - val_loss: 0.0014 - val_mae: 0.0353\n",
      "Epoch 132/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0032 - mae: 0.0469 - val_loss: 0.0014 - val_mae: 0.0350\n",
      "Epoch 133/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0032 - mae: 0.0468 - val_loss: 0.0014 - val_mae: 0.0350\n",
      "Epoch 134/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0032 - mae: 0.0470 - val_loss: 0.0014 - val_mae: 0.0360\n",
      "Epoch 135/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0032 - mae: 0.0475 - val_loss: 0.0014 - val_mae: 0.0359\n",
      "Epoch 136/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0032 - mae: 0.0471 - val_loss: 0.0014 - val_mae: 0.0352\n",
      "Epoch 137/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0032 - mae: 0.0466 - val_loss: 0.0014 - val_mae: 0.0357\n",
      "Epoch 138/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0032 - mae: 0.0480 - val_loss: 0.0015 - val_mae: 0.0364\n",
      "Epoch 139/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0032 - mae: 0.0470 - val_loss: 0.0014 - val_mae: 0.0349\n",
      "Epoch 140/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0032 - mae: 0.0466 - val_loss: 0.0014 - val_mae: 0.0350\n",
      "Epoch 141/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0463 - val_loss: 0.0014 - val_mae: 0.0355\n",
      "Epoch 142/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0032 - mae: 0.0473 - val_loss: 0.0014 - val_mae: 0.0355\n",
      "Epoch 143/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0013 - val_mae: 0.0344\n",
      "Epoch 144/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0464 - val_loss: 0.0014 - val_mae: 0.0351\n",
      "Epoch 145/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0014 - val_mae: 0.0353\n",
      "Epoch 146/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0465 - val_loss: 0.0015 - val_mae: 0.0363\n",
      "Epoch 147/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0471 - val_loss: 0.0014 - val_mae: 0.0350\n",
      "Epoch 148/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0462 - val_loss: 0.0015 - val_mae: 0.0370\n",
      "Epoch 149/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0464 - val_loss: 0.0013 - val_mae: 0.0347\n",
      "Epoch 150/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0032 - mae: 0.0472 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 151/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0014 - val_mae: 0.0353\n",
      "Epoch 152/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0462 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 153/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0464 - val_loss: 0.0014 - val_mae: 0.0350\n",
      "Epoch 154/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0465 - val_loss: 0.0014 - val_mae: 0.0349\n",
      "Epoch 155/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0465 - val_loss: 0.0014 - val_mae: 0.0345\n",
      "Epoch 156/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0461 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 157/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0460 - val_loss: 0.0014 - val_mae: 0.0348\n",
      "Epoch 158/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0014 - val_mae: 0.0351\n",
      "Epoch 159/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0460 - val_loss: 0.0014 - val_mae: 0.0356\n",
      "Epoch 160/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0031 - mae: 0.0460 - val_loss: 0.0014 - val_mae: 0.0357\n",
      "Epoch 161/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0464 - val_loss: 0.0014 - val_mae: 0.0348\n",
      "Epoch 162/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0462 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 163/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0458 - val_loss: 0.0013 - val_mae: 0.0343\n",
      "Epoch 164/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0463 - val_loss: 0.0013 - val_mae: 0.0345\n",
      "Epoch 165/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0460 - val_loss: 0.0014 - val_mae: 0.0350\n",
      "Epoch 166/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0474 - val_loss: 0.0015 - val_mae: 0.0369\n",
      "Epoch 167/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0013 - val_mae: 0.0343\n",
      "Epoch 168/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0465 - val_loss: 0.0013 - val_mae: 0.0343\n",
      "Epoch 169/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0461 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 170/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0457 - val_loss: 0.0013 - val_mae: 0.0345\n",
      "Epoch 171/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0031 - mae: 0.0457 - val_loss: 0.0014 - val_mae: 0.0363\n",
      "Epoch 172/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0461 - val_loss: 0.0013 - val_mae: 0.0343\n",
      "Epoch 173/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0031 - mae: 0.0460 - val_loss: 0.0014 - val_mae: 0.0346\n",
      "Epoch 174/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0459 - val_loss: 0.0014 - val_mae: 0.0345\n",
      "Epoch 175/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0461 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 176/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0460 - val_loss: 0.0014 - val_mae: 0.0345\n",
      "Epoch 177/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0460 - val_loss: 0.0014 - val_mae: 0.0346\n",
      "Epoch 178/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0013 - val_mae: 0.0347\n",
      "Epoch 179/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0014 - val_mae: 0.0351\n",
      "Epoch 180/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0460 - val_loss: 0.0014 - val_mae: 0.0353\n",
      "Epoch 181/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0031 - mae: 0.0459 - val_loss: 0.0015 - val_mae: 0.0371\n",
      "Epoch 182/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0014 - val_mae: 0.0351\n",
      "Epoch 183/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0463 - val_loss: 0.0014 - val_mae: 0.0358\n",
      "Epoch 184/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0464 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 185/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0030 - mae: 0.0454 - val_loss: 0.0014 - val_mae: 0.0344\n",
      "Epoch 186/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0013 - val_mae: 0.0340\n",
      "Epoch 187/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0465 - val_loss: 0.0014 - val_mae: 0.0346\n",
      "Epoch 188/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0457 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 189/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0014 - val_mae: 0.0346\n",
      "Epoch 190/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0460 - val_loss: 0.0013 - val_mae: 0.0342\n",
      "Epoch 191/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0463 - val_loss: 0.0013 - val_mae: 0.0343\n",
      "Epoch 192/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0013 - val_mae: 0.0345\n",
      "Epoch 193/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0013 - val_mae: 0.0345\n",
      "Epoch 194/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0457 - val_loss: 0.0013 - val_mae: 0.0345\n",
      "Epoch 195/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0014 - val_mae: 0.0343\n",
      "Epoch 196/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0454 - val_loss: 0.0013 - val_mae: 0.0346\n",
      "Epoch 197/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0013 - val_mae: 0.0344\n",
      "Epoch 198/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0454 - val_loss: 0.0013 - val_mae: 0.0342\n",
      "Epoch 199/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0014 - val_mae: 0.0345\n",
      "Epoch 200/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0454 - val_loss: 0.0014 - val_mae: 0.0349\n",
      "Epoch 201/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0014 - val_mae: 0.0346\n",
      "Epoch 202/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0014 - val_mae: 0.0349\n",
      "Epoch 203/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0013 - val_mae: 0.0343\n",
      "Epoch 204/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0030 - mae: 0.0452 - val_loss: 0.0014 - val_mae: 0.0366\n",
      "Epoch 205/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0014 - val_mae: 0.0346\n",
      "Epoch 206/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0030 - mae: 0.0453 - val_loss: 0.0013 - val_mae: 0.0345\n",
      "Epoch 207/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0030 - mae: 0.0450 - val_loss: 0.0014 - val_mae: 0.0368\n",
      "Epoch 208/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0030 - mae: 0.0452 - val_loss: 0.0014 - val_mae: 0.0352\n",
      "Epoch 209/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0014 - val_mae: 0.0352\n",
      "Epoch 210/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0031 - mae: 0.0463 - val_loss: 0.0021 - val_mae: 0.0488\n",
      "Epoch 211/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0032 - mae: 0.0492 - val_loss: 0.0015 - val_mae: 0.0363\n",
      "Epoch 212/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0014 - val_mae: 0.0354\n",
      "Epoch 213/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0452 - val_loss: 0.0013 - val_mae: 0.0345\n",
      "Epoch 214/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0013 - val_mae: 0.0346\n",
      "Epoch 215/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0014 - val_mae: 0.0351\n",
      "Epoch 216/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0030 - mae: 0.0455 - val_loss: 0.0014 - val_mae: 0.0346\n",
      "Epoch 217/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0450 - val_loss: 0.0014 - val_mae: 0.0361\n",
      "Epoch 218/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0014 - val_mae: 0.0344\n",
      "Epoch 219/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0461 - val_loss: 0.0016 - val_mae: 0.0391\n",
      "Epoch 220/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0452 - val_loss: 0.0014 - val_mae: 0.0355\n",
      "Epoch 221/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0014 - val_mae: 0.0362\n",
      "Epoch 222/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0030 - mae: 0.0453 - val_loss: 0.0014 - val_mae: 0.0356\n",
      "Epoch 223/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0030 - mae: 0.0451 - val_loss: 0.0014 - val_mae: 0.0344\n",
      "Epoch 224/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0014 - val_mae: 0.0350\n",
      "Epoch 225/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0013 - val_mae: 0.0345\n",
      "Epoch 226/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0454 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 227/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0452 - val_loss: 0.0014 - val_mae: 0.0353\n",
      "Epoch 228/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0030 - mae: 0.0453 - val_loss: 0.0014 - val_mae: 0.0348\n",
      "Epoch 229/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0014 - val_mae: 0.0356\n",
      "Epoch 230/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0030 - mae: 0.0453 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 231/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - mae: 0.0464 - val_loss: 0.0013 - val_mae: 0.0342\n",
      "Epoch 232/500\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0030 - mae: 0.0447 - val_loss: 0.0015 - val_mae: 0.0370\n",
      "Epoch 233/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0030 - mae: 0.0451 - val_loss: 0.0014 - val_mae: 0.0360\n",
      "Epoch 234/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0452 - val_loss: 0.0014 - val_mae: 0.0349\n",
      "Epoch 235/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0014 - val_mae: 0.0353\n",
      "Epoch 236/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0454 - val_loss: 0.0014 - val_mae: 0.0346\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33953.4617960453"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_and_evaluate(ahead_model, ahead_train_ds, ahead_valid_ds, learning_rate=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99d7aa8e-79d1-4d83-af69-e8802dedbf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33953.4617960453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2faea2e-23a8-4c47-9299-e51856f3559c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 171ms/step\n"
     ]
    }
   ],
   "source": [
    "X = mulvar_valid.to_numpy()[np.newaxis, :seq_length]  # shape [1, 56, 5]\n",
    "Y_pred = ahead_model.predict(X)  # shape [1, 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5029d34-5168-4b07-973b-c09189d6c2e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 通过 windows 时间窗口来预测未来时间步"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0bd94-74bc-48f4-b3f6-bc4b9caba207",
   "metadata": {},
   "source": [
    "Now let's create an RNN that predicts the next 14 steps at each time step. That is, instead of just forecasting time steps 56 to 69 based on time steps 0 to 55, it will forecast time steps 1 to 14 at time step 0, then time steps 2 to 15 at time step 1, and so on, and finally it will forecast time steps 56 to 69 at the last time step. Notice that the model is causal: when it makes predictions at any time step, it can only see past time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb1f99-3efa-4450-ae0d-41aedc57e935",
   "metadata": {},
   "source": [
    "To prepare the datasets, we can use `to_windows()` twice, to get sequences of consecutive windows, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "440ba913-9839-4694-9468-cf96f48a6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_windows(dataset, length):\n",
    "    dataset = dataset.window(length, shift=1, drop_remainder=True)\n",
    "    return dataset.flat_map(lambda window_ds: window_ds.batch(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "64eee473-6e96-4eb0-8aa4-772a5dc3cd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(4, 3), dtype=int64, numpy=\n",
       " array([[0, 1, 2],\n",
       "        [1, 2, 3],\n",
       "        [2, 3, 4],\n",
       "        [3, 4, 5]])>,\n",
       " <tf.Tensor: shape=(4, 3), dtype=int64, numpy=\n",
       " array([[1, 2, 3],\n",
       "        [2, 3, 4],\n",
       "        [3, 4, 5],\n",
       "        [4, 5, 6]])>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series = tf.data.Dataset.range(7)\n",
    "dataset = to_windows(to_windows(my_series, 3), 4)\n",
    "list(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5ef315-5f29-41c8-830e-d6b7b28ef66c",
   "metadata": {},
   "source": [
    "Then we can split these elements into the desired inputs and targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71eda633-57cb-49b5-8c16-50e79f632e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 1, 2, 3])>,\n",
       "  <tf.Tensor: shape=(4, 2), dtype=int64, numpy=\n",
       "  array([[1, 2],\n",
       "         [2, 3],\n",
       "         [3, 4],\n",
       "         [4, 5]])>),\n",
       " (<tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 2, 3, 4])>,\n",
       "  <tf.Tensor: shape=(4, 2), dtype=int64, numpy=\n",
       "  array([[2, 3],\n",
       "         [3, 4],\n",
       "         [4, 5],\n",
       "         [5, 6]])>)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda S: (S[:, 0], S[:, 1:]))\n",
    "list(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aad899-8f8d-4f84-ab67-2aded9af908b",
   "metadata": {},
   "source": [
    "Let's wrap this idea into a utility function. It will also take care of shuffling (optional) and batching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a736547-6319-422e-822b-0e47949b21d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seq2seq_dataset(series, seq_length=56, ahead=14, target_col=1,\n",
    "                      batch_size=32, shuffle=False, seed=None):\n",
    "    ds = to_windows(tf.data.Dataset.from_tensor_slices(series), ahead + 1)\n",
    "    ds = to_windows(ds,seq_length).map(lambda S:(S[:, 0], S[:, 1:, 1]))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(8 * batch_size, seed=seed)\n",
    "    return ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "664455ab-7b18-4735-a563-24ba2334a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_train = to_seq2seq_dataset(mulvar_train, shuffle=True, seed=42)\n",
    "seq2seq_valid = to_seq2seq_dataset(mulvar_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e5a35d5-8391-49a6-b101-b8ca818725ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
    "seq2seq_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "    # equivalent: tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(14))\n",
    "    # also equivalent: tf.keras.layers.Conv1D(14, kernel_size=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71720146-c608-4d54-8325-bf4f852cb80c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 3s 45ms/step - loss: 0.0465 - mae: 0.2230 - val_loss: 0.0135 - val_mae: 0.1272\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0109 - mae: 0.1130 - val_loss: 0.0096 - val_mae: 0.1017\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0084 - mae: 0.0970 - val_loss: 0.0081 - val_mae: 0.0916\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0071 - mae: 0.0867 - val_loss: 0.0072 - val_mae: 0.0845\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0061 - mae: 0.0784 - val_loss: 0.0058 - val_mae: 0.0742\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0056 - mae: 0.0734 - val_loss: 0.0060 - val_mae: 0.0749\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0052 - mae: 0.0695 - val_loss: 0.0054 - val_mae: 0.0695\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0050 - mae: 0.0669 - val_loss: 0.0049 - val_mae: 0.0649\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0048 - mae: 0.0652 - val_loss: 0.0045 - val_mae: 0.0605\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0047 - mae: 0.0642 - val_loss: 0.0047 - val_mae: 0.0630\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0045 - mae: 0.0630 - val_loss: 0.0048 - val_mae: 0.0640\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0044 - mae: 0.0615 - val_loss: 0.0045 - val_mae: 0.0610\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0043 - mae: 0.0604 - val_loss: 0.0046 - val_mae: 0.0624\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0042 - mae: 0.0596 - val_loss: 0.0047 - val_mae: 0.0629\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0042 - mae: 0.0596 - val_loss: 0.0043 - val_mae: 0.0585\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0042 - mae: 0.0589 - val_loss: 0.0044 - val_mae: 0.0589\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0041 - mae: 0.0583 - val_loss: 0.0042 - val_mae: 0.0575\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0041 - mae: 0.0577 - val_loss: 0.0043 - val_mae: 0.0584\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0040 - mae: 0.0576 - val_loss: 0.0042 - val_mae: 0.0571\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0040 - mae: 0.0573 - val_loss: 0.0042 - val_mae: 0.0565\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0040 - mae: 0.0569 - val_loss: 0.0043 - val_mae: 0.0576\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0040 - mae: 0.0579 - val_loss: 0.0041 - val_mae: 0.0555\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0040 - mae: 0.0571 - val_loss: 0.0041 - val_mae: 0.0554\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0040 - mae: 0.0570 - val_loss: 0.0041 - val_mae: 0.0547\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0039 - mae: 0.0562 - val_loss: 0.0041 - val_mae: 0.0557\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0039 - mae: 0.0556 - val_loss: 0.0040 - val_mae: 0.0548\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0039 - mae: 0.0557 - val_loss: 0.0040 - val_mae: 0.0545\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0039 - mae: 0.0558 - val_loss: 0.0039 - val_mae: 0.0534\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0038 - mae: 0.0552 - val_loss: 0.0039 - val_mae: 0.0532\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0038 - mae: 0.0546 - val_loss: 0.0038 - val_mae: 0.0509\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0038 - mae: 0.0548 - val_loss: 0.0040 - val_mae: 0.0538\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0037 - mae: 0.0541 - val_loss: 0.0040 - val_mae: 0.0533\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0037 - mae: 0.0539 - val_loss: 0.0038 - val_mae: 0.0516\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0037 - mae: 0.0543 - val_loss: 0.0039 - val_mae: 0.0531\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0037 - mae: 0.0535 - val_loss: 0.0039 - val_mae: 0.0531\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0037 - mae: 0.0542 - val_loss: 0.0038 - val_mae: 0.0512\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0037 - mae: 0.0546 - val_loss: 0.0039 - val_mae: 0.0526\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0037 - mae: 0.0532 - val_loss: 0.0038 - val_mae: 0.0517\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0037 - mae: 0.0535 - val_loss: 0.0038 - val_mae: 0.0518\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0036 - mae: 0.0533 - val_loss: 0.0039 - val_mae: 0.0531\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0036 - mae: 0.0533 - val_loss: 0.0038 - val_mae: 0.0514\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0036 - mae: 0.0533 - val_loss: 0.0037 - val_mae: 0.0499\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0036 - mae: 0.0532 - val_loss: 0.0040 - val_mae: 0.0536\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0036 - mae: 0.0522 - val_loss: 0.0039 - val_mae: 0.0529\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0036 - mae: 0.0526 - val_loss: 0.0038 - val_mae: 0.0511\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0036 - mae: 0.0530 - val_loss: 0.0037 - val_mae: 0.0502\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0036 - mae: 0.0535 - val_loss: 0.0037 - val_mae: 0.0500\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0036 - mae: 0.0529 - val_loss: 0.0037 - val_mae: 0.0502\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0036 - mae: 0.0528 - val_loss: 0.0038 - val_mae: 0.0504\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0035 - mae: 0.0521 - val_loss: 0.0038 - val_mae: 0.0504\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0035 - mae: 0.0519 - val_loss: 0.0038 - val_mae: 0.0515\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0035 - mae: 0.0521 - val_loss: 0.0037 - val_mae: 0.0502\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0035 - mae: 0.0518 - val_loss: 0.0038 - val_mae: 0.0514\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0035 - mae: 0.0517 - val_loss: 0.0039 - val_mae: 0.0527\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0036 - mae: 0.0529 - val_loss: 0.0038 - val_mae: 0.0515\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0036 - mae: 0.0528 - val_loss: 0.0037 - val_mae: 0.0491\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0035 - mae: 0.0521 - val_loss: 0.0038 - val_mae: 0.0510\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0035 - mae: 0.0516 - val_loss: 0.0037 - val_mae: 0.0493\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0035 - mae: 0.0515 - val_loss: 0.0038 - val_mae: 0.0503\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0035 - mae: 0.0513 - val_loss: 0.0037 - val_mae: 0.0492\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0035 - mae: 0.0523 - val_loss: 0.0037 - val_mae: 0.0495\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0035 - mae: 0.0521 - val_loss: 0.0038 - val_mae: 0.0504\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0035 - mae: 0.0528 - val_loss: 0.0037 - val_mae: 0.0498\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0034 - mae: 0.0511 - val_loss: 0.0038 - val_mae: 0.0500\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0034 - mae: 0.0512 - val_loss: 0.0039 - val_mae: 0.0520\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0034 - mae: 0.0511 - val_loss: 0.0037 - val_mae: 0.0496\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0035 - mae: 0.0517 - val_loss: 0.0038 - val_mae: 0.0500\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0508 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0503 - val_loss: 0.0037 - val_mae: 0.0489\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0034 - mae: 0.0510 - val_loss: 0.0037 - val_mae: 0.0493\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0505 - val_loss: 0.0038 - val_mae: 0.0507\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0508 - val_loss: 0.0037 - val_mae: 0.0490\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0034 - mae: 0.0511 - val_loss: 0.0037 - val_mae: 0.0498\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0036 - mae: 0.0533 - val_loss: 0.0038 - val_mae: 0.0518\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0507 - val_loss: 0.0039 - val_mae: 0.0516\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0509 - val_loss: 0.0037 - val_mae: 0.0485\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0034 - mae: 0.0510 - val_loss: 0.0037 - val_mae: 0.0488\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0501 - val_loss: 0.0037 - val_mae: 0.0486\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0502 - val_loss: 0.0037 - val_mae: 0.0489\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0509 - val_loss: 0.0037 - val_mae: 0.0492\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0034 - mae: 0.0510 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0034 - mae: 0.0505 - val_loss: 0.0037 - val_mae: 0.0491\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0034 - mae: 0.0500 - val_loss: 0.0038 - val_mae: 0.0499\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0497 - val_loss: 0.0037 - val_mae: 0.0486\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0034 - mae: 0.0503 - val_loss: 0.0037 - val_mae: 0.0488\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0034 - mae: 0.0504 - val_loss: 0.0037 - val_mae: 0.0482\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0503 - val_loss: 0.0037 - val_mae: 0.0484\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0499 - val_loss: 0.0037 - val_mae: 0.0484\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0033 - mae: 0.0502 - val_loss: 0.0037 - val_mae: 0.0497\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0492 - val_loss: 0.0037 - val_mae: 0.0489\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0494 - val_loss: 0.0038 - val_mae: 0.0499\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0033 - mae: 0.0495 - val_loss: 0.0037 - val_mae: 0.0484\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0503 - val_loss: 0.0037 - val_mae: 0.0488\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0035 - mae: 0.0525 - val_loss: 0.0036 - val_mae: 0.0482\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0506 - val_loss: 0.0039 - val_mae: 0.0523\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0495 - val_loss: 0.0036 - val_mae: 0.0480\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0503 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0498 - val_loss: 0.0036 - val_mae: 0.0478\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0033 - mae: 0.0503 - val_loss: 0.0037 - val_mae: 0.0484\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0491 - val_loss: 0.0037 - val_mae: 0.0483\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0033 - mae: 0.0500 - val_loss: 0.0036 - val_mae: 0.0480\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0033 - mae: 0.0493 - val_loss: 0.0037 - val_mae: 0.0490\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0491 - val_loss: 0.0038 - val_mae: 0.0505\n",
      "Epoch 104/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0491 - val_loss: 0.0038 - val_mae: 0.0513\n",
      "Epoch 105/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0033 - mae: 0.0491 - val_loss: 0.0037 - val_mae: 0.0486\n",
      "Epoch 106/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0033 - mae: 0.0492 - val_loss: 0.0037 - val_mae: 0.0489\n",
      "Epoch 107/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0483 - val_loss: 0.0038 - val_mae: 0.0498\n",
      "Epoch 108/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 109/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0033 - mae: 0.0492 - val_loss: 0.0037 - val_mae: 0.0485\n",
      "Epoch 110/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0033 - mae: 0.0492 - val_loss: 0.0037 - val_mae: 0.0491\n",
      "Epoch 111/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0494 - val_loss: 0.0037 - val_mae: 0.0487\n",
      "Epoch 112/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0034 - mae: 0.0512 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 113/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0033 - mae: 0.0503 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 114/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0033 - mae: 0.0490 - val_loss: 0.0037 - val_mae: 0.0496\n",
      "Epoch 115/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0491 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 116/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0493 - val_loss: 0.0037 - val_mae: 0.0489\n",
      "Epoch 117/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0485 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 118/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0033 - mae: 0.0494 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 119/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0496 - val_loss: 0.0038 - val_mae: 0.0499\n",
      "Epoch 120/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 121/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 122/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0037 - val_mae: 0.0482\n",
      "Epoch 123/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0037 - val_mae: 0.0491\n",
      "Epoch 124/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0487 - val_loss: 0.0037 - val_mae: 0.0477\n",
      "Epoch 125/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0488 - val_loss: 0.0037 - val_mae: 0.0494\n",
      "Epoch 126/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0037 - val_mae: 0.0476\n",
      "Epoch 127/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0037 - val_mae: 0.0474\n",
      "Epoch 128/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0033 - mae: 0.0502 - val_loss: 0.0037 - val_mae: 0.0497\n",
      "Epoch 129/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0495 - val_loss: 0.0037 - val_mae: 0.0492\n",
      "Epoch 130/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0490 - val_loss: 0.0037 - val_mae: 0.0488\n",
      "Epoch 131/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0033 - mae: 0.0498 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 132/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0489 - val_loss: 0.0037 - val_mae: 0.0483\n",
      "Epoch 133/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0485 - val_loss: 0.0037 - val_mae: 0.0482\n",
      "Epoch 134/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0478 - val_loss: 0.0037 - val_mae: 0.0482\n",
      "Epoch 135/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0485 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 136/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0491 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 137/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0492 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 138/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0487 - val_loss: 0.0039 - val_mae: 0.0519\n",
      "Epoch 139/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0477 - val_loss: 0.0037 - val_mae: 0.0483\n",
      "Epoch 140/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0037 - val_mae: 0.0483\n",
      "Epoch 141/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0037 - val_mae: 0.0487\n",
      "Epoch 142/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 143/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0488 - val_loss: 0.0037 - val_mae: 0.0480\n",
      "Epoch 144/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0033 - mae: 0.0496 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 145/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0485 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 146/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0481 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 147/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 148/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 149/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0491 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 150/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 151/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0487 - val_loss: 0.0037 - val_mae: 0.0485\n",
      "Epoch 152/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 153/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 154/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0487 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 155/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0488 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 156/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0478 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 157/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 158/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0480 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 159/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0474 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 160/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0481 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 161/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 162/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0481 - val_loss: 0.0036 - val_mae: 0.0467\n",
      "Epoch 163/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0479 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 164/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 165/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 166/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0037 - val_mae: 0.0482\n",
      "Epoch 167/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0037 - val_mae: 0.0495\n",
      "Epoch 168/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0037 - val_mae: 0.0485\n",
      "Epoch 169/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0488 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 170/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0036 - val_mae: 0.0480\n",
      "Epoch 171/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 172/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0031 - mae: 0.0482 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 173/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 174/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 175/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 176/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 177/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0479 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 178/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 179/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0477 - val_loss: 0.0036 - val_mae: 0.0465\n",
      "Epoch 180/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 181/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0480 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 182/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0036 - val_mae: 0.0467\n",
      "Epoch 183/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 184/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 185/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0031 - mae: 0.0469 - val_loss: 0.0037 - val_mae: 0.0482\n",
      "Epoch 186/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0485 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 187/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0031 - mae: 0.0474 - val_loss: 0.0036 - val_mae: 0.0467\n",
      "Epoch 188/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0469 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 189/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 190/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 191/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0038 - val_mae: 0.0506\n",
      "Epoch 192/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 193/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0487 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 194/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0481 - val_loss: 0.0036 - val_mae: 0.0465\n",
      "Epoch 195/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0482 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 196/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0480\n",
      "Epoch 197/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 198/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0036 - val_mae: 0.0466\n",
      "Epoch 199/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0036 - val_mae: 0.0466\n",
      "Epoch 200/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 201/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 202/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0036 - val_mae: 0.0467\n",
      "Epoch 203/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0474 - val_loss: 0.0036 - val_mae: 0.0465\n",
      "Epoch 204/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0036 - val_mae: 0.0466\n",
      "Epoch 205/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0477 - val_loss: 0.0036 - val_mae: 0.0478\n",
      "Epoch 206/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 207/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 208/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0036 - val_mae: 0.0466\n",
      "Epoch 209/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0478\n",
      "Epoch 210/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0031 - mae: 0.0469 - val_loss: 0.0036 - val_mae: 0.0467\n",
      "Epoch 211/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0469 - val_loss: 0.0036 - val_mae: 0.0467\n",
      "Epoch 212/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0469 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 213/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0465\n",
      "Epoch 214/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 215/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0031 - mae: 0.0469 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 216/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 217/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0466\n",
      "Epoch 218/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 219/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0467\n",
      "Epoch 220/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0467\n",
      "Epoch 221/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0036 - val_mae: 0.0484\n",
      "Epoch 222/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 223/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0469 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 224/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 225/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 226/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 227/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 228/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0037 - val_mae: 0.0496\n",
      "Epoch 229/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0036 - val_mae: 0.0481\n",
      "Epoch 230/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0469 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 231/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 232/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0469 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 233/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0035 - val_mae: 0.0466\n",
      "Epoch 234/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0480 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 235/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 236/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0470 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 237/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 238/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0036 - val_mae: 0.0467\n",
      "Epoch 239/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0036 - val_mae: 0.0485\n",
      "Epoch 240/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 241/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0470 - val_loss: 0.0035 - val_mae: 0.0469\n",
      "Epoch 242/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0466\n",
      "Epoch 243/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 244/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 245/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 246/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0480 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 247/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 248/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 249/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 250/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 251/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 252/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 253/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0035 - val_mae: 0.0468\n",
      "Epoch 254/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0467\n",
      "Epoch 255/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0469 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 256/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 257/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0035 - val_mae: 0.0460\n",
      "Epoch 258/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 259/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 260/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 261/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0035 - val_mae: 0.0470\n",
      "Epoch 262/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 263/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0469 - val_loss: 0.0035 - val_mae: 0.0467\n",
      "Epoch 264/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0470 - val_loss: 0.0035 - val_mae: 0.0460\n",
      "Epoch 265/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0035 - val_mae: 0.0461\n",
      "Epoch 266/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 267/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0035 - val_mae: 0.0469\n",
      "Epoch 268/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 269/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0468\n",
      "Epoch 270/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0466\n",
      "Epoch 271/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0035 - val_mae: 0.0467\n",
      "Epoch 272/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 273/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0473 - val_loss: 0.0035 - val_mae: 0.0466\n",
      "Epoch 274/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 275/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0035 - val_mae: 0.0461\n",
      "Epoch 276/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 277/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 278/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0474 - val_loss: 0.0035 - val_mae: 0.0467\n",
      "Epoch 279/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0035 - val_mae: 0.0468\n",
      "Epoch 280/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 281/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 282/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0466\n",
      "Epoch 283/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 284/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 285/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 286/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0479 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 287/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0460\n",
      "Epoch 288/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 289/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0467\n",
      "Epoch 290/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 291/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 292/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0035 - val_mae: 0.0467\n",
      "Epoch 293/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0037 - val_mae: 0.0514\n",
      "Epoch 294/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 295/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 296/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0035 - val_mae: 0.0466\n",
      "Epoch 297/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 298/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 299/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0469 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 300/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 301/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 302/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0035 - val_mae: 0.0468\n",
      "Epoch 303/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 304/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0480\n",
      "Epoch 305/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 306/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 307/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0470 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 308/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 309/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 310/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0461\n",
      "Epoch 311/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0035 - val_mae: 0.0473\n",
      "Epoch 312/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0035 - val_mae: 0.0468\n",
      "Epoch 313/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 314/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0035 - val_mae: 0.0466\n",
      "Epoch 315/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 316/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 317/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0469\n",
      "Epoch 318/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 319/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0035 - val_mae: 0.0461\n",
      "Epoch 320/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0461\n",
      "Epoch 321/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 322/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0035 - val_mae: 0.0461\n",
      "Epoch 323/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0035 - val_mae: 0.0466\n",
      "Epoch 324/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 325/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0471 - val_loss: 0.0034 - val_mae: 0.0458\n",
      "Epoch 326/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0467 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 327/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0035 - val_mae: 0.0460\n",
      "Epoch 328/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 329/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0035 - val_mae: 0.0461\n",
      "Epoch 330/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 331/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0457 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 332/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0035 - val_mae: 0.0466\n",
      "Epoch 333/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0035 - val_mae: 0.0473\n",
      "Epoch 334/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0035 - val_mae: 0.0461\n",
      "Epoch 335/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0453 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 336/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 337/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0035 - val_mae: 0.0460\n",
      "Epoch 338/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0035 - val_mae: 0.0460\n",
      "Epoch 339/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0459\n",
      "Epoch 340/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 341/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0035 - val_mae: 0.0461\n",
      "Epoch 342/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0036 - val_mae: 0.0497\n",
      "Epoch 343/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 344/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 345/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0035 - val_mae: 0.0477\n",
      "Epoch 346/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0487\n",
      "Epoch 347/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 348/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0453 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 349/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0452 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 350/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0034 - val_mae: 0.0459\n",
      "Epoch 351/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0035 - val_mae: 0.0466\n",
      "Epoch 352/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 353/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0470\n",
      "Epoch 354/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0452 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 355/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0035 - val_mae: 0.0481\n",
      "Epoch 356/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0031 - mae: 0.0479 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 357/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0035 - val_mae: 0.0474\n",
      "Epoch 358/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0035 - val_mae: 0.0475\n",
      "Epoch 359/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0453 - val_loss: 0.0034 - val_mae: 0.0462\n",
      "Epoch 360/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 361/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0034 - val_mae: 0.0458\n",
      "Epoch 362/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0457 - val_loss: 0.0035 - val_mae: 0.0467\n",
      "Epoch 363/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0034 - val_mae: 0.0461\n",
      "Epoch 364/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0034 - val_mae: 0.0459\n",
      "Epoch 365/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 366/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0034 - val_mae: 0.0458\n",
      "Epoch 367/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0035 - val_mae: 0.0472\n",
      "Epoch 368/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 369/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0458 - val_loss: 0.0035 - val_mae: 0.0470\n",
      "Epoch 370/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 371/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0453 - val_loss: 0.0034 - val_mae: 0.0461\n",
      "Epoch 372/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0035 - val_mae: 0.0472\n",
      "Epoch 373/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0034 - val_mae: 0.0464\n",
      "Epoch 374/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 375/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 376/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0453 - val_loss: 0.0035 - val_mae: 0.0476\n",
      "Epoch 377/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0468\n",
      "Epoch 378/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 379/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 380/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0034 - val_mae: 0.0459\n",
      "Epoch 381/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0035 - val_mae: 0.0467\n",
      "Epoch 382/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0470\n",
      "Epoch 383/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0452 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 384/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0453 - val_loss: 0.0035 - val_mae: 0.0472\n",
      "Epoch 385/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0469\n",
      "Epoch 386/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 387/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0034 - val_mae: 0.0461\n",
      "Epoch 388/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0034 - val_mae: 0.0461\n",
      "Epoch 389/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0457 - val_loss: 0.0034 - val_mae: 0.0464\n",
      "Epoch 390/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0453 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 391/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0453 - val_loss: 0.0034 - val_mae: 0.0459\n",
      "Epoch 392/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0034 - val_mae: 0.0461\n",
      "Epoch 393/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0034 - val_mae: 0.0462\n",
      "Epoch 394/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0458 - val_loss: 0.0035 - val_mae: 0.0467\n",
      "Epoch 395/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0034 - val_mae: 0.0459\n",
      "Epoch 396/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0036 - val_mae: 0.0484\n",
      "Epoch 397/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0450 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 398/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 399/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0034 - val_mae: 0.0462\n",
      "Epoch 400/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0450 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 401/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0034 - val_mae: 0.0461\n",
      "Epoch 402/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0452 - val_loss: 0.0034 - val_mae: 0.0461\n",
      "Epoch 403/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0450 - val_loss: 0.0034 - val_mae: 0.0461\n",
      "Epoch 404/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0035 - val_mae: 0.0473\n",
      "Epoch 405/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0502\n",
      "Epoch 406/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0034 - val_mae: 0.0459\n",
      "Epoch 407/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0034 - val_mae: 0.0459\n",
      "Epoch 408/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 409/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0457 - val_loss: 0.0034 - val_mae: 0.0459\n",
      "Epoch 410/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0029 - mae: 0.0452 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 411/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0451 - val_loss: 0.0035 - val_mae: 0.0468\n",
      "Epoch 412/500\n",
      "33/33 [==============================] - 1s 13ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0035 - val_mae: 0.0479\n",
      "Epoch 413/500\n",
      "33/33 [==============================] - 1s 14ms/step - loss: 0.0029 - mae: 0.0460 - val_loss: 0.0035 - val_mae: 0.0463\n",
      "Epoch 414/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0449 - val_loss: 0.0034 - val_mae: 0.0461\n",
      "Epoch 415/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0454 - val_loss: 0.0034 - val_mae: 0.0461\n",
      "Epoch 416/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0034 - val_mae: 0.0463\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0034 - mae: 0.0458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45762.94124126434"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_and_evaluate(seq2seq_model, seq2seq_train, seq2seq_valid,\n",
    "                 learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79b6545b-698c-4779-8f79-87d6a247c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 45762.94124126434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d1e89b7-d98f-4d4f-b865-c964479cfa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 203ms/step\n"
     ]
    }
   ],
   "source": [
    "X = mulvar_valid.to_numpy()[np.newaxis, :seq_length]\n",
    "y_pred_14 = seq2seq_model.predict(X)[0, -1]  # only the last time step's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b6750a7-64a4-4b22-a975-f0159bc51645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 16ms/step\n",
      "MAE for +1: 24,469\n",
      "MAE for +2: 29,069\n",
      "MAE for +3: 29,081\n",
      "MAE for +4: 30,855\n",
      "MAE for +5: 32,694\n",
      "MAE for +6: 33,788\n",
      "MAE for +7: 32,946\n",
      "MAE for +8: 34,636\n",
      "MAE for +9: 33,487\n",
      "MAE for +10: 33,542\n",
      "MAE for +11: 37,626\n",
      "MAE for +12: 36,927\n",
      "MAE for +13: 35,697\n",
      "MAE for +14: 33,981\n"
     ]
    }
   ],
   "source": [
    "Y_pred_valid = seq2seq_model.predict(seq2seq_valid)\n",
    "for ahead in range(14):\n",
    "    preds = pd.Series(Y_pred_valid[:-1, -1, ahead],\n",
    "                      index=mulvar_valid.index[56 + ahead : -14 + ahead])\n",
    "    mae = (preds - mulvar_valid[\"rail\"]).abs().mean() * 1e6\n",
    "    print(f\"MAE for +{ahead + 1}: {mae:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235a02c-179d-4ea8-819e-1e3edcb2c9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "343eaa89-996c-44f2-a9b7-2a821696f400",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep RNNs with Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688f23b-e9dd-408c-a0a1-93cadd2c0bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class LNSimpleRNNCell(tf.keras.layers.Layer):\n",
    "#     def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.state_size = units\n",
    "#         self.output_size = units\n",
    "#         self.simple_rnn_cell = tf.keras.layers.SimpleRNNCell(units, activation=None)\n",
    "#         self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "#         self.activation = tf.keras.activations.get(activation)\n",
    "    \n",
    "#     def call(self, inputs, states):\n",
    "#         outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "#         norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "#         return norm_outputs, [norm_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ef6f7-b998-45c9-acaf-1dceef9a2876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(42)\n",
    "# custom_ln_model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.RNN(LNSimpleRNNCell(32), return_sequences=True, input_shape=[None, 5]),\n",
    "#     tf.keras.layers.Dense(14)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f023b8c7-0faa-4457-926b-656cfd57b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_and_evaluate(custom_ln_model, seq2seq_train, seq2seq_valid, learning_rate=0.1, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78c306-f8e8-46a1-a6b9-8a690f28a3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.13",
   "language": "python",
   "name": "tf2.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
