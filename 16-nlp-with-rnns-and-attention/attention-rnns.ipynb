{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6694d346-9aa1-4c1e-a8a1-71cc3b96e90f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d2df6d-e912-43fb-8294-d9287dbe8928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50fc349a-1dea-4f02-8662-69c634e14c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 19:50:20.798936: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-13 19:50:21.231445: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-13 19:50:24.217811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "import tensorflow as tf\n",
    "\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12fbcfb-de4d-4ecc-b017-8fd41cac4eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f4fa33-cf71-4082-96f0-8e2e90d34298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"nlp\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21dfa9-171b-44ab-b83e-e25888170eae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generating Shakespearean Text Using a Character RNN\n",
    "使用字符RNN生成莎士比亚文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb168ac6-e3a1-443b-83e7-780c99ae1411",
   "metadata": {},
   "source": [
    "## Creating the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587f67c-55f0-440b-b355-6e4d45515669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "shakespeare_url = \"https://homl.info/shakespeare\"  # shortcut URL\n",
    "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08854b-19db-4097-bcfe-9eaa27718685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows a short text sample\n",
    "print(shakespeare_text[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39ff57-cc17-4ba6-ba39-65bc0a9e1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows all 39 distinct characters (after converting to lower case)\n",
    "\"\".join(sorted(set(shakespeare_text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e7c0f-52d9-43e6-8125-63d42ef63b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\",\n",
    "                                                   standardize=\"lower\")\n",
    "text_vec_layer.adapt([shakespeare_text])\n",
    "encoded = text_vec_layer([shakespeare_text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce7121-9715-47cb-84ad-370fdf1f831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded -= 2  # drop tokens 0 (pad) and 1 (unknown), which we will not use\n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2  # number of distinct chars = 39\n",
    "dataset_size = len(encoded)  # total number of chars = 1,115,394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153bbec-4554-40b3-8a35-f9b2153a9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100_000, seed=seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eee9d4-5c24-49b5-90f1-ef5a70adbe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – a simple example using to_dataset()\n",
    "# There's just one sample in this dataset: the input represents \"to b\" and the\n",
    "# output represents \"o be\"\n",
    "list(to_dataset(text_vec_layer([\"To be\"])[0], length=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbfc176-d678-48e5-81f2-37a535204ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 100\n",
    "tf.random.set_seed(42)\n",
    "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True,\n",
    "                       seed=42)\n",
    "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
    "test_set = to_dataset(encoded[1_060_000:], length=length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b0a3d-0bc7-4895-8864-95c9ebc715db",
   "metadata": {},
   "source": [
    "## Building and Training the Char-RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca55457-7919-48d4-a75f-0a82338b242c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.13",
   "language": "python",
   "name": "tf2.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
